INSERT INTO options values ( 470,'A. Use Stackdriver Logging to search for the module log entries.',TRUE,112) ;
INSERT INTO options values ( 471,'B. Read the debug GCE Activity log using the API or Cloud Console.',FALSE,112) ;
INSERT INTO options values ( 472,'C. Use gcloud or Cloud Console to connect to the serial console and observe the logs.',TRUE,112) ;
INSERT INTO options values ( 473,'D. Identify whether a live migration event of the failed server occurred, using in the activity log. ',FALSE,112) ;
INSERT INTO options values ( 474,'E. Adjust the Google Stackdriver timeline to match the failure time, and observe the batch server metrics.',TRUE,112) ;
INSERT INTO options values ( 475,'F. Export a debug VM into an image, and run the image on a local server where kernel log messages will be displayed on the native screen.',FALSE,112) ;
INSERT INTO options values ( 476,'A. Load logs into Google BigQuery. ',TRUE,113) ;
INSERT INTO options values ( 477,'B. Load logs into Google Cloud SQL.',FALSE,113) ;
INSERT INTO options values ( 478,'C. Import logs into Google Stackdriver. ',FALSE,113) ;
INSERT INTO options values ( 479,'D. Insert logs into Google Cloud Bigtable.',FALSE,113) ;
INSERT INTO options values ( 480,'E. Upload log files into Google Cloud Storage.',TRUE,113) ;
INSERT INTO options values ( 481,'A. Ensure that a firewall rule exists to allow source traffic on HTTP/HTTPS to reach the load balancer. ',FALSE,114) ;
INSERT INTO options values ( 482,'B. Assign a public IP to each instance and configure a firewall rule to allow the load balancer to reach the instance public IP.',FALSE,114) ;
INSERT INTO options values ( 483,'C. Ensure that a firewall rule exists to allow load balancer health checks to reach the instances in the instance group.',TRUE,114) ;
INSERT INTO options values ( 484,'D. Create a tag on each instance with the name of the load balancer. Configure a firewall rule with the name of the load balancer as the source and the instance tag as the destination.',FALSE,114) ;
INSERT INTO options values ( 485,'A. Google BigQuery ',FALSE,115) ;
INSERT INTO options values ( 486,'B. Google Cloud SQL',FALSE,115) ;
INSERT INTO options values ( 487,'C. Google Cloud Bigtable ',TRUE,115) ;
INSERT INTO options values ( 488,'D. Google Cloud Storage',FALSE,115) ;
INSERT INTO options values ( 489,'A. Increase the virtual machine''s memory to 64 GB. ',FALSE,116) ;
INSERT INTO options values ( 490,'B. Create a new virtual machine running PostgreSQL.',FALSE,116) ;
INSERT INTO options values ( 491,'C. Dynamically resize the SSD persistent disk to 500 GB.',TRUE,116) ;
INSERT INTO options values ( 492,'D. Migrate their performance metrics warehouse to BigQuery.',FALSE,116) ;
INSERT INTO options values ( 493,'E. Modify all of their batch jobs to use bulk inserts into the database.',FALSE,116) ;
INSERT INTO options values ( 494,'A. Create a tokenizer service and store only tokenized data. ',TRUE,117) ;
INSERT INTO options values ( 495,'B. Create separate projects that only process credit card data.',FALSE,117) ;
INSERT INTO options values ( 496,'C. Create separate subnetworks and isolate the components that process credit card data.',FALSE,117) ;
INSERT INTO options values ( 497,'D. Streamline the audit discovery phase by labeling all of the virtual machines (VMs) that process PCI data.',FALSE,117) ;
INSERT INTO options values ( 498,'E. Enable Logging export to Google BigQuery and use ACLs and views to scope the data shared with the auditor.',FALSE,117) ;
INSERT INTO options values ( 499,'A. Google Cloud SQL',FALSE,118) ;
INSERT INTO options values ( 500,'B. Google Cloud Bigtable ',FALSE,118) ;
INSERT INTO options values ( 501,'C. Google Cloud Storage ',FALSE,118) ;
INSERT INTO options values ( 502,'D. Google cloud Datastore',FALSE,118) ;
INSERT INTO options values ( 503,'A. Work with your ISP to diagnose the problem.',FALSE,119) ;
INSERT INTO options values ( 504,'B. Open a support ticket to ask for network capture and flow data to diagnose the problem, then roll back your application.',FALSE,119) ;
INSERT INTO options values ( 505,'C. Roll back to an earlier known good release initially, then use Stackdriver Trace and logging to diagnose the problem in a development/test/staging environment.',TRUE,119) ;
INSERT INTO options values ( 506,'D. Roll back to an earlier known good release, then push the release again at a quieter period to investigate. Then use Stackdriver Trace and logging to diagnose the problem.',FALSE,119) ;
INSERT INTO options values ( 507,'A. Google Cloud Dataproc ',FALSE,120) ;
INSERT INTO options values ( 508,'B. Google Cloud Dataflow',TRUE,120) ;
INSERT INTO options values ( 509,'C. Google Container Engine with Bigtable',FALSE,120) ;
INSERT INTO options values ( 510,'D. Google Compute Engine with Google BigQuery',FALSE,120) ;
INSERT INTO options values ( 511,'A. Use G Suite Password Sync to replicate passwords into Google.',FALSE,121) ;
INSERT INTO options values ( 512,'B. Federate authentication via SAML 2.0 to the existing Identity Provider. ',TRUE,121) ;
INSERT INTO options values ( 513,'C. Provision users in Google using the Google Cloud Directory Sync tool.',FALSE,121) ;
INSERT INTO options values ( 514,'D. Ask users to set their Google password to match their corporate password',FALSE,121) ;
INSERT INTO options values ( 515,'A. Flat file ',FALSE,122) ;
INSERT INTO options values ( 516,'B. NoSQL',TRUE,122) ;
INSERT INTO options values ( 517,'C. Relational ',FALSE,122) ;
INSERT INTO options values ( 518,'D. Blobstore',FALSE,122) ;
INSERT INTO options values ( 519,'A. Introduce a green-blue deployment model.',TRUE,123) ;
INSERT INTO options values ( 520,'B. Replace the QA environment with canary releases.',FALSE,123) ;
INSERT INTO options values ( 521,'C. Fragment the monolithic platform into microservices.',TRUE,123) ;
INSERT INTO options values ( 522,'D. Reduce the platform''s dependency on relational database systems.',FALSE,123) ;
INSERT INTO options values ( 523,'E. Replace the platform''s relational database systems with a NoSQL database.',FALSE,123) ;
INSERT INTO options values ( 524,'A. Direct them to download and install the Google StackDriver logging agent. ',FALSE,124) ;
INSERT INTO options values ( 525,'B. Send them a list of online resources about logging best practices.',FALSE,124) ;
INSERT INTO options values ( 526,'C. Help them define their requirements and assess viable logging tools.',TRUE,124) ;
INSERT INTO options values ( 527,'D. Help them upgrade their current tool to take advantage of any new features.',FALSE,124) ;
INSERT INTO options values ( 528,'A. The session variable is local to just a single instance.',TRUE,125) ;
INSERT INTO options values ( 529,'B. The session variable is being overwritten in Cloud Datastore. ',FALSE,125) ;
INSERT INTO options values ( 530,'C. The URL of the API needs to be modified to prevent caching. ',FALSE,125) ;
INSERT INTO options values ( 531,'D. The HTTP Expires header needs to be set to -1 to stop caching.',FALSE,125) ;
INSERT INTO options values ( 532,'A. Load data into Google BigQuery. ',TRUE,126) ;
INSERT INTO options values ( 533,'B. Insert data into Google Cloud SQL.',FALSE,126) ;
INSERT INTO options values ( 534,'C. Put flat files into Google Cloud Storage. ',FALSE,126) ;
INSERT INTO options values ( 535,'D. Stream data into Google Cloud Datastore.',FALSE,126) ;
INSERT INTO options values ( 536,'A. Org viewer, project owner ',FALSE,127) ;
INSERT INTO options values ( 537,'B. Org viewer, project viewer ',TRUE,127) ;
INSERT INTO options values ( 538,'C. Org admin, project browser',FALSE,127) ;
INSERT INTO options values ( 539,'D. Project owner, network admin',FALSE,127) ;
INSERT INTO options values ( 540,'A. Ensure every code check-in is peer reviewed by a security SME. ',FALSE,128) ;
INSERT INTO options values ( 541,'B. Use source code security analyzers as part of the CI/CD pipeline.',TRUE,128) ;
INSERT INTO options values ( 542,'C. Ensure you have stubs to unit test all interfaces between components.',FALSE,128) ;
INSERT INTO options values ( 543,'D. Enable code signing and a trusted binary repository integrated with your CI/CD pipeline.',FALSE,128) ;
INSERT INTO options values ( 544,'E. Run a vulnerability security scanner as part of your continuous-integration /continuous-delivery (CI/CD) pipeline.',TRUE,128) ;
INSERT INTO options values ( 545,'A. Ensure that the load tests validate the performance of Cloud Bigtable.',TRUE,129) ;
INSERT INTO options values ( 546,'B. Create a separate Google Cloud project to use for the load-testing environment.',TRUE,129) ;
INSERT INTO options values ( 547,'C. Schedule the load-testing tool to regularly run against the production environment. ',FALSE,129) ;
INSERT INTO options values ( 548,'D. Ensure all third-party systems your services use are capable of handling high load.',FALSE,129) ;
INSERT INTO options values ( 549,'E. Instrument the production services to record every transaction for replay by the load-testing tool. ',FALSE,129) ;
INSERT INTO options values ( 550,'F. Instrument the load-testing tool and the target services with detailed logging and metrics collection.',TRUE,129) ;
INSERT INTO options values ( 551,'A. Use the Linux dd and netcat command to copy and stream the root disk contents to a new virtual machine instance in the US-East region.',FALSE,130) ;
INSERT INTO options values ( 552,'B. Create a snapshot of the root disk and select the snapshot as the root disk when you create a new virtual machine instance in the US-East region.',FALSE,130) ;
INSERT INTO options values ( 553,'C. Create an image file from the root disk with Linux dd command, create a new disk from the image file, and use it to create a new virtual machine instance in the US-East region',FALSE,130) ;
INSERT INTO options values ( 554,'D. Create a snapshot of the root disk, create an image file in Google Cloud Storage from the snapshot, and create a new virtual machine instance in the US-East region using the image file for the root disk.',TRUE,130) ;
INSERT INTO options values ( 555,'A. Configure a cron job to use the gcloud tool to take regular backups using persistent disk snapshots. ',FALSE,131) ;
INSERT INTO options values ( 556,'B. Mount a Local SSD volume as the backup location. After the backup is complete, use gsutil to move the backup to Google Cloud Storage.',TRUE,131) ;
INSERT INTO options values ( 557,'C. Use gcsfuse to mount a Google Cloud Storage bucket as a volume directly on the instance and write backups to the mounted location using mysqldump',FALSE,131) ;
INSERT INTO options values ( 558,'D. Mount additional persistent disk volumes onto each virtual machine (VM) instance in a RAID10 array and use LVM to create snapshots to send to Cloud Storage.',FALSE,131) ;
INSERT INTO options values ( 559,'A. Upload missing JAR files and redeploy your application.',FALSE,132) ;
INSERT INTO options values ( 560,'B. Digitally sign all of your JAR files and redeploy your application',TRUE,132) ;
INSERT INTO options values ( 561,'C. Recompile the CLoakedServlet class using and MD5 hash instead of SHA1',FALSE,132) ;
INSERT INTO options values ( 562,'A. • Append metadata to file body. • Compress individual files.• Name files with serverName-Timestamp.• Create a new bucket if bucket is older than 1 hour and save individual files to the new bucket. Otherwise, save files to existing bucket',FALSE,133) ;
INSERT INTO options values ( 563,'B. • Batch every 10,000 events with a single manifest file for metadata. • Compress event files and manifest file into a single archive file.• Name files using serverName-EventSequence. • Create a new bucket if bucket is older than 1 day and save the single archive file to the new bucket. Otherwise, save the single archive file to existing bucket.',FALSE,133) ;
INSERT INTO options values ( 564,'C. • Compress individual files. • Name files with serverName-EventSequence. • Save files to one bucket • Set custom metadata headers for each object after saving.',FALSE,133) ;
INSERT INTO options values ( 565,'D. • Append metadata to file body. • Compress individual files. • Name files with a random prefix pattern. • Save files to one bucket',TRUE,133) ;
INSERT INTO options values ( 566,'A. Help the engineer to convert his websocket code to use HTTP streaming.',FALSE,134) ;
INSERT INTO options values ( 567,'B. Review the encryption requirements for websocket connections with the security team. ',FALSE,134) ;
INSERT INTO options values ( 568,'C. Meet with the cloud operations team and the engineer to discuss load balancer options.',TRUE,134) ;
INSERT INTO options values ( 569,'D. Help the engineer redesign the application to use a distributed user session service that does not rely on websockets and HTTP sessions.',FALSE,134) ;
INSERT INTO options values ( 570,'A. Add additional nodes to your Container Engine cluster using the following command: gcloud container clusters resize CLUSTER_NAME --size 10',FALSE,135) ;
INSERT INTO options values ( 571,'B. Add a tag to the instances in the cluster with the following command: gcloud compute instances add-tags INSTANCE --tags enable --autoscaling max-nodes-10 ',TRUE,135) ;
INSERT INTO options values ( 572,'C. Update the existing Container Engine cluster with the following command: gcloud alpha container clusters update mycluster --enable-autoscaling --min-nodes=1 --max-nodes=10',FALSE,135) ;
INSERT INTO options values ( 573,'D. Create a new Container Engine cluster with the following command:gcloud alpha container clusters create mycluster --enable-autocaling --min-nodes=1 --max-nodes=10 and redeploy your application.',FALSE,135) ;
INSERT INTO options values ( 574,'A. Recompile the CLoakedServlet class using and MD5 hash instead of SHA1 ',FALSE,136) ;
INSERT INTO options values ( 575,'B. Digitally sign all of your JAR files and redeploy your application.',TRUE,136) ;
INSERT INTO options values ( 576,'C. Upload missing JAR files and redeploy your application',FALSE,136) ;
INSERT INTO options values ( 577,'A. Tag messages client side with the originating user identifier and the destination user. ',FALSE,137) ;
INSERT INTO options values ( 578,'B. Encrypt the message client side using block-based encryption with a shared key.',FALSE,137) ;
INSERT INTO options values ( 579,'C. Use public key infrastructure (PKI) to encrypt the message client side using the originating user''s private key.',TRUE,137) ;
INSERT INTO options values ( 580,'D. Use a trusted certificate authority to enable SSL connectivity between the client application and the server.',FALSE,137) ;
INSERT INTO options values ( 581,'A. Log in to a server, and iterate a fix locally',FALSE,138) ;
INSERT INTO options values ( 582,'B. Change the instance group template to the previous one, and delete all instances. ',FALSE,138) ;
INSERT INTO options values ( 583,'C. Revert the source code change and rerun the deployment pipeline',TRUE,138) ;
INSERT INTO options values ( 584,'D. Log into the servers with the bad code change, and swap in the previous code',FALSE,138) ;
INSERT INTO options values ( 585,'A. Multiple Organizations with multiple Folders',FALSE,139) ;
INSERT INTO options values ( 586,'B. Multiple Organizations, one for each department',FALSE,139) ;
INSERT INTO options values ( 587,'C. A single Organization with Folder for each department',TRUE,139) ;
INSERT INTO options values ( 588,'D. A single Organization with multiple projects, each with a central owner',FALSE,139) ;
INSERT INTO options values ( 589,'A. Search for Create VM entry in the Stackdriver alerting console..',FALSE,140) ;
INSERT INTO options values ( 590,'B. Navigate to the Activity page in the Home section. Set category to Data Access and search for Create VM entry.',FALSE,140) ;
INSERT INTO options values ( 591,'C. In the logging section of the console, specify GCE Network as the logging section. Search for the Create Insert entry.',TRUE,140) ;
INSERT INTO options values ( 592,'D. Connect to the GCE instance using project SSH Keys. Identify previous logins in system logs, and match these with the project owners list',FALSE,140) ;
INSERT INTO options values ( 593,'A. Configure their replication to use UDP.',FALSE,141) ;
INSERT INTO options values ( 594,'B. Configure a Google Cloud Dedicated Interconnect.',TRUE,141) ;
INSERT INTO options values ( 595,'C. Restore their database daily using Google Cloud SQL.',FALSE,141) ;
INSERT INTO options values ( 596,'D. Add additional VPN connections and load balance them. ',FALSE,141) ;
INSERT INTO options values ( 597,'E. Send the replicated transaction to Google Cloud Pub/Sub.',FALSE,141) ;
INSERT INTO options values ( 598,'A. Hash all data using SHA256',FALSE,142) ;
INSERT INTO options values ( 599,'B. Encrypt all data using elliptic curve cryptography',FALSE,142) ;
INSERT INTO options values ( 600,'C. De-identify the data with the Cloud Data Loss Prevention API',TRUE,142) ;
INSERT INTO options values ( 601,'D. Use regular expressions to find and redact phone numbers, email addresses, and credit card numbers',FALSE,142) ;
INSERT INTO options values ( 602,'A. ~/bin',TRUE,143) ;
INSERT INTO options values ( 603,'B. Cloud Storage ',FALSE,143) ;
INSERT INTO options values ( 604,'C. /google/scripts ',FALSE,143) ;
INSERT INTO options values ( 605,'D. /usr/local/bin',FALSE,143) ;
INSERT INTO options values ( 606,'A. Create a VPC and connect it to your on-premises data center using Dedicated Interconnect. ',FALSE,144) ;
INSERT INTO options values ( 607,'B. Create a VPC and connect it to your on-premises data center using a single Cloud VPN.',TRUE,144) ;
INSERT INTO options values ( 608,'C. Create a Cloud Content Delivery Network (Cloud CDN) and connect it to your on-premises data center using Dedicated Interconnect.',FALSE,144) ;
INSERT INTO options values ( 609,'D. Create a Cloud Content Delivery Network (Cloud CDN) and connect it to your on-premises datacenter using a single Cloud VPN.',FALSE,144) ;
INSERT INTO options values ( 610,'A. Utilize free tier and sustained use discounts. Provision a staff position for service cost management.',FALSE,145) ;
INSERT INTO options values ( 611,'B. Utilize free tier and sustained use discounts. Provide training to the team about service cost management.',FALSE,145) ;
INSERT INTO options values ( 612,'C. Utilize free tier and committed use discounts. Provision a staff position for service cost management.',TRUE,145) ;
INSERT INTO options values ( 613,'D. Utilize free tier and committed use discounts. Provide training to the team about service cost management.',FALSE,145) ;
INSERT INTO options values ( 614,'A. Use Spinnaker to deploy builds to production using the red/black deployment strategy so that changes can easily be rolled back.',TRUE,146) ;
INSERT INTO options values ( 615,'B. Use Spinnaker to deploy builds to production and run tests on production deployments.',FALSE,146) ;
INSERT INTO options values ( 616,'C. Use Jenkins to build the staging branches and the master branch. Build and deploy changes to production for 10% of users before doing a complete rollout.',FALSE,146) ;
INSERT INTO options values ( 617,'D. Use Jenkins to monitor tags in the repository. Deploy staging tags to a staging environment for testing.After testing, tag the repository for production and deploy that to the production environment.',FALSE,146) ;
INSERT INTO options values ( 618,'A. Grant your colleague the IAM role of project Viewer ',TRUE,147) ;
INSERT INTO options values ( 619,'B. Perform a rolling restart on the instance group',FALSE,147) ;
INSERT INTO options values ( 620,'C. Disable the health check for the instance group. Add his SSH key to the project-wide SSH keys ',FALSE,147) ;
INSERT INTO options values ( 621,'D. Disable autoscaling for the instance group. Add his SSH key to the project-wide SSH Keys',FALSE,147) ;
INSERT INTO options values ( 622,'A. App Engine is the only compute platform on GCP that is certified for PCI DSS hosting.',FALSE,148) ;
INSERT INTO options values ( 623,'B. Kubernetes Engine cannot be used under PCI DSS because it is considered shared hosting.',TRUE,148) ;
INSERT INTO options values ( 624,'C. Kubernetes Engine and GCP provide the tools you need to build a PCI DSS-compliant environment. ',FALSE,148) ;
INSERT INTO options values ( 625,'D. All Google Cloud services are usable because Google Cloud Platform is certified PCI-compliant.',FALSE,148) ;
INSERT INTO options values ( 626,'A. Upload your files into Cloud Storage. Use Cloud Datalab to explore and clean your data. ',FALSE,149) ;
INSERT INTO options values ( 627,'B. Upload your files into Cloud Storage. Use Cloud Dataprep to explore and clean your data.',FALSE,149) ;
INSERT INTO options values ( 628,'C. Connect Cloud Datalab to your on-premises systems. Use Cloud Datalab to explore and clean your data.',FALSE,149) ;
INSERT INTO options values ( 629,'D. Connect Cloud Dataprep to your on-premises systems. Use Cloud Dataprep to explore and clean',TRUE,149) ;
INSERT INTO options values ( 630,'A. The effective policy is determined only by the policy set at the node',FALSE,150) ;
INSERT INTO options values ( 631,'B. The effective policy is the policy set at the node and restricted by the policies of its ancestors ',FALSE,150) ;
INSERT INTO options values ( 632,'C. The effective policy is the union of the policy set at the node and policies inherited from its ancestors',TRUE,150) ;
INSERT INTO options values ( 633,'D. The effective policy is the intersection of the policy set at the node and policies inherited from its ancestors',FALSE,150) ;
INSERT INTO options values ( 634,'A. Use the same IP range on Google Cloud as you use on-premises',FALSE,151) ;
INSERT INTO options values ( 635,'B. Use the same IP range on Google Cloud as you use on-premises for your primary IP range and use a secondary range that does not overlap with the range you use on-premises',FALSE,151) ;
INSERT INTO options values ( 636,'C. Use an IP range on Google Cloud that does not overlap with the range you use on-premises',TRUE,151) ;
INSERT INTO options values ( 637,'D. Use an IP range on Google Cloud that does not overlap with the range you use on-premises for your primary IP range and use a secondary range with the same IP range as you use on-premises',FALSE,151) ;
INSERT INTO options values ( 638,'A. Point gcloud datastore create-indexes to your configuration file',FALSE,152) ;
INSERT INTO options values ( 639,'B. Upload the configuration file the App Engine’s default Cloud Storage bucket, and have App Engine detect the new indexes',TRUE,152) ;
INSERT INTO options values ( 640,'C. In the GCP Console, use Datastore Admin to delete the current indexes and upload the new configuration file',FALSE,152) ;
INSERT INTO options values ( 641,'D. Create an HTTP request to the built-in python module to send the index configuration file to your application',FALSE,152) ;
INSERT INTO options values ( 642,'A. Deploy the application on two Compute Engine instances in the same project but in a different region. Use the first instance to serve traffic, and use the HTTP load balancing service to fail over to the standby instance in case of a disaster.',FALSE,153) ;
INSERT INTO options values ( 643,'B. Deploy the application on a Compute Engine instance. Use the instance to serve traffic, and use the HTTP load balancing service to fail over to an instance on your premises in case of a disaster.',FALSE,153) ;
INSERT INTO options values ( 644,'C. Deploy the application on two Compute Engine instance groups, each in the same project but in a different region. Use the first instance group to serve traffic, and use the HTTP load balancing service to fail over to the standby instance group in case of a disaster.',TRUE,153) ;
INSERT INTO options values ( 645,'D. Deploy the application on two Compute Engine instance groups, each in separate project and a different region. Use the first instance group to server traffic, and use the HTTP load balancing service to fail over to the standby instance in case of a disaster.',FALSE,153) ;
INSERT INTO options values ( 646,'A. Deploy your application on App Engine standard environment and use App Engine firewall rules to limit access to the open on-premises database.',FALSE,154) ;
INSERT INTO options values ( 647,'B. Deploy your application on App Engine standard environment and use Cloud VPN to limit access to the onpremises database.',FALSE,154) ;
INSERT INTO options values ( 648,'C. Deploy your application on App Engine flexible environment and use App Engine firewall rules to limit access to the on-premises database.',FALSE,154) ;
INSERT INTO options values ( 649,'D. Deploy your application on App Engine flexible environment and use Cloud VPN to limit access to the on-premises database.',TRUE,154) ;
INSERT INTO options values ( 650,'A. Upload the required installation files to Cloud Storage. Configure the VM on a subnet with a Private Google Access subnet. Assign only an internal IP address to the VM. Download the installation files to the VM using gsutil.',TRUE,155) ;
INSERT INTO options values ( 651,'B. Upload the required installation files to Cloud Storage and use firewall rules to block all traffic except the IP address range for Cloud Storage. Download the files to the VM using gsutil.',FALSE,155) ;
INSERT INTO options values ( 652,'C. Upload the required installation files to Cloud Source Repositories. Configure the VM on a subnet with a Private Google Access subnet. Assign only an internal IP address to the VM. Download the installation files to the VM using gcloud.',FALSE,155) ;
INSERT INTO options values ( 653,'D. Upload the required installation files to Cloud Source Repositories and use firewall rules to block all traffic except the IP address range for Cloud Source Repositories. Download the files to the VM using gsutil.',FALSE,155) ;
INSERT INTO options values ( 654,'A. Move your data onto a Transfer Appliance. Use a Transfer Appliance Rehydrator to decrypt the data into Cloud Storage.',TRUE,156) ;
INSERT INTO options values ( 655,'B. Move your data onto a Transfer Appliance. Use Cloud Dataprep to decrypt the data into Cloud Storage.',FALSE,156) ;
INSERT INTO options values ( 656,'C. Install gsutil on each server that contains data. Use resumable transfers to upload the data into Cloud Storage.',FALSE,156) ;
INSERT INTO options values ( 657,'D. Install gsutil on each server containing data. Use streaming transfers to upload the data into Cloud Storage.',FALSE,156) ;
INSERT INTO options values ( 658,'A. Use kubect1 set image deployment/echo-deployment <new-image>',TRUE,157) ;
INSERT INTO options values ( 659,'B. Use the rolling update functionality of the Instance Group behind the Kubernetes cluster',FALSE,157) ;
INSERT INTO options values ( 660,'C. Update the deployment yaml file with the new container image. Use kubect1 delete deployment/ echo-deployment and kubect1 create –f <yaml-file>',FALSE,157) ;
INSERT INTO options values ( 661,'D. Update the service yaml file which the new container image. Use kubect1 delete service/echoservice and kubect1 create –f <yaml-file>',FALSE,157) ;
INSERT INTO options values ( 662,'A. Add all users to a group. Grant the group the role of BigQuery user on the billing project and BigQuery dataViewer on the projects that contain the data.',FALSE,158) ;
INSERT INTO options values ( 663,'B. Add all users to a group. Grant the group the roles of BigQuery dataViewer on the billing project and BigQuery user on the projects that contain the data.',FALSE,158) ;
INSERT INTO options values ( 664,'C. Add all users to a group. Grant the group the roles of BigQuery jobUser on the billing project and BigQuery dataViewer on the projects that contain the data.',TRUE,158) ;
INSERT INTO options values ( 665,'D. Add all users to a group. Grant the group the roles of BigQuery dataViewer on the billing project and BigQuery jobUser on the projects that contain the data.',FALSE,158) ;
INSERT INTO options values ( 666,'A. Have users upload the images to Cloud Storage. Protect the bucket with a password that expires after 24 hours.',FALSE,159) ;
INSERT INTO options values ( 667,'B. Have users upload the images to Cloud Storage using a signed URL that expires after 24 hours. ',TRUE,159) ;
INSERT INTO options values ( 668,'C. Create an App Engine web application where users can upload images. Configure App Engine to disable the application after 24 hours. Authenticate users via Cloud Identity.',FALSE,159) ;
INSERT INTO options values ( 669,'D. Create an App Engine web application where users can upload images for the next 24 hours. Authenticate users via Cloud Identity.',FALSE,159) ;
INSERT INTO options values ( 670,'A. Ensure that your web application only uses native features and services of Google Cloud Platform, because Google already has various certifications and provides “pass-on” compliance when you use native features.',FALSE,160) ;
INSERT INTO options values ( 671,'B. Enable the relevant GDPR compliance setting within the GCPConsole for each of the services in use within your application.',FALSE,160) ;
INSERT INTO options values ( 672,'C. Ensure that Cloud Security Scanner is part of your test planning strategy in order to pick up any compliance gaps.',FALSE,160) ;
INSERT INTO options values ( 673,'D. Define a design for the security of data in your web application that meets GDPR requirements.',TRUE,160) ;
INSERT INTO options values ( 674,'A. Configure a Cloud SQL instance with high availability enabled.',TRUE,161) ;
INSERT INTO options values ( 675,'B. Configure a Cloud Spanner instance with a regional instance configuration.',FALSE,161) ;
INSERT INTO options values ( 676,'C. Set up SQL Server on Compute Engine, using Always On Availability Groups using Windows Failover Clustering. Place nodes in different subnets.',FALSE,161) ;
INSERT INTO options values ( 677,'D. Set up SQL Server Always On Availability Groups using Windows Failover Clustering. Place nodes in different zones.',FALSE,161) ;
INSERT INTO options values ( 678,'A. Use gcloud to create a Kubernetes cluster. Use Deployment Manager to create the deployment. ',FALSE,162) ;
INSERT INTO options values ( 679,'B. Use gcloud to create a Kubernetes cluster. Use kubect1 to create the deployment.',TRUE,162) ;
INSERT INTO options values ( 680,'C. Use kubect1 to create a Kubernetes cluster. Use Deployment Manager to create the deployment. ',FALSE,162) ;
INSERT INTO options values ( 681,'D. Use kubect1 to create a Kubernetes cluster. Use kubect1 to create the deployment.',FALSE,162) ;
INSERT INTO options values ( 682,'A. Allocate budget for team training. Set a deadline for the new GCP project.',FALSE,163) ;
INSERT INTO options values ( 683,'B. Allocate budget for team training. Create a roadmap for your team to achieve Google Cloud certification based on job role.',TRUE,163) ;
INSERT INTO options values ( 684,'C. Allocate budget to hire skilled external consultants. Set a deadline for the new GCP project.',FALSE,163) ;
INSERT INTO options values ( 685,'D. Allocate budget to hire skilled external consultants. Create a roadmap for your team to achieve Google Cloud certification based on job role.',FALSE,163) ;
INSERT INTO options values ( 686,'A. Cloud Functions ',TRUE,164) ;
INSERT INTO options values ( 687,'B. Compute Engine',FALSE,164) ;
INSERT INTO options values ( 688,'C. Kubernetes Engine',FALSE,164) ;
INSERT INTO options values ( 689,'D. AppEngine flexible environment',FALSE,164) ;
INSERT INTO options values ( 690,'A. Create the Key object for each Entity and run a batch get operation',TRUE,165) ;
INSERT INTO options values ( 691,'B. Create the Key object for each Entity and run multiple get operations, one operation for each entity',FALSE,165) ;
INSERT INTO options values ( 692,'C. Use the identifiers to create a query filter and run a batch query operation',FALSE,165) ;
INSERT INTO options values ( 693,'D. Use the identifiers to create a query filter and run multiple query operations, one operation for each entity',FALSE,165) ;
INSERT INTO options values ( 694,'A. Supply the encryption key in a .boto configuration file. Use gsutil to upload the files.',TRUE,166) ;
INSERT INTO options values ( 695,'B. Supply the encryption key using gcloud config. Use gsutil to upload the files to that bucket.',FALSE,166) ;
INSERT INTO options values ( 696,'C. Use gsutil to upload the files, and use the flag --encryption-key to supply the encryption key.',FALSE,166) ;
INSERT INTO options values ( 697,'D. Use gsutil to create a bucket, and use the flag --encryption-key to supply the encryption key. Use gsutil to upload the files to that bucket.',FALSE,166) ;
INSERT INTO options values ( 698,'A. Store time-series data from the game servers in Google Bigtable, and view it using Google Data Studio.',FALSE,167) ;
INSERT INTO options values ( 699,'B. Output custom metrics to Stackdriver from the game servers, and create a Dashboard in Stackdriver Monitoring Console to view them.',TRUE,167) ;
INSERT INTO options values ( 700,'C. Schedule BigQuery load jobs to ingest analytics files uploaded to Cloud Storage every ten minutes, and visualize the results in Google Data Studio.',FALSE,167) ;
INSERT INTO options values ( 701,'D. Insert the KPIs into Cloud Datastore entities, and run ad hoc analysis and visualizations of them in Cloud Datalab.',FALSE,167) ;
INSERT INTO options values ( 702,'A. Perform the following: 1) Create a managed instance group with f1-micro type machines.2) Use a startup script to clone the repository, check out the production branch, install the dependencies, and start the Python app. 3) Restart the instances to automatically deploy new production releases. ',FALSE,168) ;
INSERT INTO options values ( 703,'B. Perform the following: 1) Create a managed instance group with n1-standard-1 type machines. 2) Build a Compute Engine image from the production branch that contains all of the dependencies and automatically starts the Python app. 3) Rebuild the Compute Engine image, and update the instance template to deploy new production releases.',FALSE,168) ;
INSERT INTO options values ( 704,'C. Perform the following:1) Create a Kubernetes Engine cluster with n1-standard-1 type machines.2) Build a Docker image from the production branch with all of the dependencies, and tag it with the version number.3) Create a Kubernetes Deployment with the imagePullPolicy set to “IfNotPresent” in the staging namespace, and then promote it to the production namespace after testing.',TRUE,168) ;
INSERT INTO options values ( 705,'D. Perform the following:1) Create a Kubernetes Engine (GKE) cluster with n1-standard-4 type machines.2) Build a Docker image from the master branch will all of the dependencies, and tag it with “latest”. 3) Create a Kubernetes Deployment in the default namespace with the imagePullPolicy set to“Always”.Restart the pods to automatically deploy new production releases.',FALSE,168) ;
INSERT INTO options values ( 706,'A. Use the Admin Directory API to authenticate against the Active Directory domain controller.',TRUE,169) ;
INSERT INTO options values ( 707,'B. Use Google Cloud Directory Sync to synchronize Active Directory usernames with cloud identities and configure SAML SSO.',FALSE,169) ;
INSERT INTO options values ( 708,'C. Use Cloud Identity-Aware Proxy configured to use the on-premises Active Directory domain controller as an identity provider.',FALSE,169) ;
INSERT INTO options values ( 709,'D. Use Compute Engine to create an Active Directory (AD) domain controller that is a replica of the on-premises AD domain controller using Google Cloud Directory Sync.',FALSE,169) ;
INSERT INTO options values ( 710,'A. Review the Stackdriver logs for each Compute Engine instance that is serving as a node in the cluster.',FALSE,170) ;
INSERT INTO options values ( 711,'B. Review the Stackdriver logs for the specific Kubernetes Engine container that is serving the unresponsive part of the application.',TRUE,170) ;
INSERT INTO options values ( 712,'C. Connect to the cluster using gcloud credentials and connect to a container in one of the pods to read the logs.',FALSE,170) ;
INSERT INTO options values ( 713,'D. Review the Serial Port logs for each Compute Engine instance that is serving as a node in the cluster.',FALSE,170) ;
INSERT INTO options values ( 714,'A. Create a read replica instance in a different region',FALSE,171) ;
INSERT INTO options values ( 715,'B. Create a failover replica instance in a different region',TRUE,171) ;
INSERT INTO options values ( 716,'C. Create a read replica instance in the same region, but in a different zone',FALSE,171) ;
INSERT INTO options values ( 717,'D. Create a failover replica instance in the same region, but in a different zone',FALSE,171) ;
INSERT INTO options values ( 718,'A. Create a snapshot of the existing disk. Create an instance template from the snapshot. Create an autoscaled managed instance group from the instance template.',FALSE,172) ;
INSERT INTO options values ( 719,'B. Create a snapshot of the existing disk. Create a custom image from the snapshot. Create an autoscaled managed instance group from the custom image.',FALSE,172) ;
INSERT INTO options values ( 720,'C. Create a custom image from the existing disk. Create an instance template from the custom image. Create an autoscaled managed instance group from the instance template.',FALSE,172) ;
INSERT INTO options values ( 721,'D. Create an instance template from the existing disk. Create a custom image from the instance template.Create an autoscaled managed instance group from the custom image.',TRUE,172) ;
INSERT INTO options values ( 722,'A. Use separate VPCs to restrict traffic',FALSE,173) ;
INSERT INTO options values ( 723,'B. Use firewall rules based on network tags attached to the compute instances ',FALSE,173) ;
INSERT INTO options values ( 724,'C. Use Cloud DNS and only allow connections from authorized hostnames',TRUE,173) ;
INSERT INTO options values ( 725,'D. Use service accounts and configure the web application particular service accounts to have access',FALSE,173) ;
INSERT INTO options values ( 726,'A. 1) Enable automatic storage increase for the instance.2) Create a Stackdriver alert when CPU usage exceeds 75%, and change the instance type to reduce CPU usage.3) Create a Stackdriver alert for replication lag, and shard the database to reduce replication time. ',TRUE,174) ;
INSERT INTO options values ( 727,'B. 1) Enable automatic storage increase for the instance.2) Change the instance type to a 32-core machine type to keep CPU usage below 75%.3) Create a Stackdriver alert for replication lag, and shard the database to reduce replication time. ',FALSE,174) ;
INSERT INTO options values ( 728,'C. 1) Create a Stackdriver alert when storage exceeds 75%, and increase the available storage on the instance to create more space.2) Deploy memcached to reduce CPU load.3) Change the instance type to a 32-core machine type to reduce replication lag.',FALSE,174) ;
INSERT INTO options values ( 729,'D. 1) Create a Stackdriver alert when storage exceeds 75%, and increase the available storage on the instance to create more space.2) Deploy memcached to reduce CPU load.3) Create a Stackdriver alert for replication lag, and change the instance type to a 32-core machine type to reduce replication lag.',FALSE,174) ;
INSERT INTO options values ( 730,'A. Cloud Spanner, because it is globally distributed',FALSE,175) ;
INSERT INTO options values ( 731,'B. Cloud SQL, because it is a fully managed relational database',FALSE,175) ;
INSERT INTO options values ( 732,'C. Cloud Firestore, because it offers real-time synchronization across devices ',FALSE,175) ;
INSERT INTO options values ( 733,'D. BigQuery, because it is designed for large-scale processing of tabular data',TRUE,175) ;
INSERT INTO options values ( 734,'A. Use gcloud sql instances restart.',FALSE,176) ;
INSERT INTO options values ( 735,'B. Validate that the Service Account used by the Cloud SQL proxy container still has the Cloud Build Editor role.',FALSE,176) ;
INSERT INTO options values ( 736,'C. In the GCP Console, navigate to Stackdriver Logging. Consult logs for Kubernetes Engine and Cloud SQL.',TRUE,176) ;
INSERT INTO options values ( 737,'D. In the GCP Console, navigate to Cloud SQL. Restore the latest backup. Use kubect1 to restart all pods.',FALSE,176) ;
INSERT INTO options values ( 738,'A. Ensure that VM service accounts are granted the appropriate Cloud Pub/Sub IAM roles.',TRUE,177) ;
INSERT INTO options values ( 739,'B. Ensure that VM service accounts do not have access to Cloud Pub/Sub, and use VM access scopes togrant the appropriate Cloud Pub/Sub IAM roles.',FALSE,177) ;
INSERT INTO options values ( 740,'C. Generate an OAuth2 access token for accessing Cloud Pub/Sub, encrypt it, and store it in Cloud Storage for access from each VM.',FALSE,177) ;
INSERT INTO options values ( 741,'D. Create a gateway to Cloud Pub/Sub using a Cloud Function, and grant the Cloud Function serviceaccount the appropriate Cloud Pub/Sub IAM roles',FALSE,177) ;
INSERT INTO options values ( 742,'A. Use VPC Network Peering between the VPC and the on-premises network. ',FALSE,178) ;
INSERT INTO options values ( 743,'B. Expose the VPC to the on-premises network using IAM and VPC Sharing.',FALSE,178) ;
INSERT INTO options values ( 744,'C. Create a global Cloud VPN Gateway with VPN tunnels from each region to the on-premises peer gateway.',FALSE,178) ;
INSERT INTO options values ( 745,'D. Deploy Cloud VPN Gateway in each region. Ensure that each region has at least one VPN tunnel to the on-premises peer gateway.',TRUE,178) ;
INSERT INTO options values ( 746,'A. Configure the expiration time for your tables at 45 days',FALSE,179) ;
INSERT INTO options values ( 747,'B. Make the tables time-partitioned, and configure the partition expiration at 45 days ',TRUE,179) ;
INSERT INTO options values ( 748,'C. Rely on BigQuery’s default behavior to prune application logs older than 45 days',FALSE,179) ;
INSERT INTO options values ( 749,'D. Create a script that uses the BigQuery command line tool (bq) to remove records older than 45 days',FALSE,179) ;
INSERT INTO options values ( 750,'A. Configure a HorizontalPodAutoscaler with a target CPU usage. Enable the Cluster Autoscaler from the GCP Console.',TRUE,180) ;
INSERT INTO options values ( 751,'B. Configure a HorizontalPodAutoscaler with a target CPU usage. Enable autoscaling on the managed instance group for the cluster using the gcloud command.',FALSE,180) ;
INSERT INTO options values ( 752,'C. Create a deployment and set the maxUnavailable and maxSurge properties. Enable the Cluster Autoscaler using the gcloud command.',FALSE,180) ;
INSERT INTO options values ( 753,'D. Create a deployment and set the maxUnavailable and maxSurge properties. Enable autoscaling on the cluster managed instance group from the GCP ',FALSE,180) ;
INSERT INTO options values ( 754,'A. Verify that Dedicated Interconnect can replicate files to GCP. Verify that direct peering can establish a secure connection between your networks if Dedicated Interconnect fails.',FALSE,181) ;
INSERT INTO options values ( 755,'B. Verify that Dedicated Interconnect can replicate files to GCP. Verify that Cloud VPN can establish a secure connection between your networks if Dedicated Interconnect fails.',TRUE,181) ;
INSERT INTO options values ( 756,'C. Verify that the Transfer Appliance can replicate files to GCP. Verify that direct peering can establish a secure connection between your networks if the Transfer Appliance fails.',FALSE,181) ;
INSERT INTO options values ( 757,'D. Verify that the Transfer Appliance can replicate files to GCP. Verify that Cloud VPN can establish a secure connection between your networks if the Transfer Appliance fails.',FALSE,181) ;
INSERT INTO options values ( 758,'A. Provisioning preemptible VMs to reduce cost. Discontinue use of all GCP services and APIs that are not HIPAA-compliant.',FALSE,182) ;
INSERT INTO options values ( 759,'B. Provisioning preemptible VMs to reduce cost. Disable and then discontinue use of all GCP and APIs',TRUE,182) ;
INSERT INTO options values ( 760,'C. Provision standard VMs in the same region to reduce cost. Discontinue use of all GCP services and APIs that are not HIPAA-compliant.',FALSE,182) ;
INSERT INTO options values ( 761,'D. Provision standard VMs to the same region to reduce cost. Disable and then discontinue use of all GCP services and APIs that are not HIPAA-compliant.',FALSE,182) ;
INSERT INTO options values ( 762,'A. Engage with a security company to run web scrapes that look your users’ authentication data om malicious websites and notify you if any if found.',FALSE,183) ;
INSERT INTO options values ( 763,'B. Deploy intrusion detection software to your virtual machines to detect and log unauthorized access.',FALSE,183) ;
INSERT INTO options values ( 764,'C. Schedule a disaster simulation exercise during which you can shut off all VMs in a zone to see how your application behaves.',TRUE,183) ;
INSERT INTO options values ( 765,'D. Configure a red replica for your Cloud SQL instance in a different zone than the master, and then manually trigger a failover while monitoring KPIs for our REST API.',FALSE,183) ;
INSERT INTO options values ( 766,'A. Connect Google Data Studio to BigQuery. Create a dimension for the users and a metric for the amount of queries per user.',FALSE,184) ;
INSERT INTO options values ( 767,'B. In the BigQuery interface, execute a query on the JOBS table to get the required information. ',FALSE,184) ;
INSERT INTO options values ( 768,'C. Use ‘bq show’ to list all jobs. Per job, use ‘bq Is’ to list job information and get the required information.',FALSE,184) ;
INSERT INTO options values ( 769,'D. Use Cloud Audit Logging to view Cloud Audit Logs, and create a filter on the query operation to get the required information.',TRUE,184) ;
INSERT INTO options values ( 770,'A. Use Terraform to create the managed instance group and a startup script to install the OS package dependencies.',FALSE,185) ;
INSERT INTO options values ( 771,'B. Create a custom VM image with all OS package dependencies. Use Deployment Manager to create the managed instance group with the VM image.',TRUE,185) ;
INSERT INTO options values ( 772,'C. Use Puppet to create the managed instance group and install the OS package dependencies. ',FALSE,185) ;
INSERT INTO options values ( 773,'D. Use Deployment Manager to create the managed instance group and Ansible to install the OS package dependencies.',FALSE,185) ;
INSERT INTO options values ( 774,'A. Create a group per country. Add analysts to their respective country-groups. Create a single group ‘all_analysts’, and add all country-groups as members. Grant the ‘all-analysis’ group the IAM role of BigQuery jobUser. Share the appropriate dataset with view access with each respective analyst country-group.',TRUE,186) ;
INSERT INTO options values ( 775,'B. Create a group per country. Add analysts to their respective country-groups. Create a single group ‘all_analysts’, and add all country-groups as members. Grant the ‘all-analysis’ group the IAM role of BigQuery jobUser. Share the appropriate tables with view access with each respective analyst countrygroup.',FALSE,186) ;
INSERT INTO options values ( 776,'C. Create a group per country. Add analysts to their respective country-groups. Create a single group ‘all_analysts’, and add all country-groups as members. Grant the ‘all-analysis’ group the IAM role of BigQuery dataViewer. Share the appropriate dataset with view access with each respective analyst country-group.',FALSE,186) ;
INSERT INTO options values ( 777,'D. Create a group per country. Add analysts to their respective country-groups. Create a single group ‘all_analysts’, and add all country-groups as members. Grant the ‘all-analysis’ group the IAM role of BigQuery dataViewer. Share the appropriate table with view access with each respective analyst countrygroup.',FALSE,186) ;
INSERT INTO options values ( 778,'A. Local SSD for customer session state datA. Lifecycle-managed Cloud Storage for log archives, thumbnails, and VM boot/data volumes.',FALSE,187) ;
INSERT INTO options values ( 779,'B. Memcache backed by Cloud Datastore for the customer session state datA. Lifecycle- managed Cloud',FALSE,187) ;
INSERT INTO options values ( 780,'C. Memcache backed by Cloud SQL for customer session state datA. Assorted local SSD-backed instances for VM boot/data volumes. Cloud Storage for log archives and thumbnails.',FALSE,187) ;
INSERT INTO options values ( 781,'D. Memcache backed by Persistent Disk SSD storage for customer session state datA. Assorted local SSDbacked instances for VM boot/data volumes. Cloud Storage for log archives and thumbnails.',TRUE,187) ;
INSERT INTO options values ( 782,'A. StatefulSets',TRUE,188) ;
INSERT INTO options values ( 783,'B. Role-based access control',FALSE,188) ;
INSERT INTO options values ( 784,'C. Container environment variables ',FALSE,188) ;
INSERT INTO options values ( 785,'D. Persistent Volumes',FALSE,188) ;
INSERT INTO options values ( 786,'A. Customize the cache keys to omit the protocol from the key. ',TRUE,189) ;
INSERT INTO options values ( 787,'B. Shorten the expiration time of the cached objects.',FALSE,189) ;
INSERT INTO options values ( 788,'C. Make sure the HTTP(S) header “Cache-Region” points to the closest region of your users.',FALSE,189) ;
INSERT INTO options values ( 789,'D. Replicate the static content in a Cloud Storage bucket. Point CloudCDN toward a load balancer on that bucket.',FALSE,189) ;
INSERT INTO options values ( 790,'A. All admin and VM system logs are automatically collected by Stackdriver.',FALSE,190) ;
INSERT INTO options values ( 791,'B. Stackdriver automatically collects admin activity logs for most services. The Stackdriver Logging agent must be installed on each instance to collect system logs.',TRUE,190) ;
INSERT INTO options values ( 792,'C. Launch a custom syslogd compute instance and configure your GCP project and VMs to forward all logs to it.',FALSE,190) ;
INSERT INTO options values ( 793,'D. Install the Stackdriver Logging agent on a single compute instance and let it collect all audit and access logs for your environment.',FALSE,190) ;
INSERT INTO options values ( 794,'A. Deploy the update using the Instance Group Updater to create a partial rollout, which allows for canary',FALSE,191) ;
INSERT INTO options values ( 795,'B. Deploy the update as a new version in the App Engine application, and split traffic between the new and current versions.',TRUE,191) ;
INSERT INTO options values ( 796,'C. Deploy the update in a new VPC, and use Google’s global HTTP load balancing to split traffic between the update and current applications.',FALSE,191) ;
INSERT INTO options values ( 797,'D. Deploy the update as a new App Engine application, and use Google’s global HTTP load balancing to split traffic between the new and current applications.',FALSE,191) ;
INSERT INTO options values ( 798,'A. Create an egress rule with priority 1000 to deny all traffic for all instances. Create another egress rule with priority 100 to allow the Active Directory traffic for all instances.',TRUE,192) ;
INSERT INTO options values ( 799,'B. Create an egress rule with priority 100 to deny all traffic for all instances. Create another egress rule with priority 1000 to allow the Active Directory traffic for all instances.',FALSE,192) ;
INSERT INTO options values ( 800,'C. Create an egress rule with priority 1000 to allow the Active Directory traffic. Rely on the implied deny egress rule with priority 100 to block all traffic for all instances.',FALSE,192) ;
INSERT INTO options values ( 801,'D. Create an egress rule with priority 100 to allow the Active Directory traffic. Rely on the implied deny egress rule with priority 1000 to block all traffic for all instances.',FALSE,192) ;
INSERT INTO options values ( 802,'A. Export Cloud Machine Learning Engine performance metrics from Stackdriver to BigQuery, to be used to analyze the eficiency of the model.',FALSE,193) ;
INSERT INTO options values ( 803,'B. Build a roadmap to move the machine learning model training from Cloud GPUs to Cloud TPUs, which offer better results.',FALSE,193) ;
INSERT INTO options values ( 804,'C. Monitor Compute Engine announcements for availability of newer CPU architectures, and deploy the model to them as soon as they are available for additional performance.',FALSE,193) ;
INSERT INTO options values ( 805,'D. Save a history of recommendations and results of the recommendations in BigQuery, to be used as training data.',TRUE,193) ;
INSERT INTO options values ( 806,'A. Use the Horizontal Pod Autoscaler and enable cluster autoscaling. Use an Ingress resource to loadbalance the HTTPS traffic.',TRUE,194) ;
INSERT INTO options values ( 807,'B. Use the Horizontal Pod Autoscaler and enable cluster autoscaling on the Kubernetes cluster. Use a Service resource of type LoadBalancer to load-balance the HTTPS traffic.',FALSE,194) ;
INSERT INTO options values ( 808,'C. Enable autoscaling on the Compute Engine instance group. Use an Ingress resource to load balance the HTTPS traffic.',FALSE,194) ;
INSERT INTO options values ( 809,'D. Enable autoscaling on the Compute Engine instance group. Use a Service resource of type LoadBalancer to load-balance the HTTPS traffic.',FALSE,194) ;
INSERT INTO options values ( 810,'A. Create a cross-region load balancer with URL Maps. ',FALSE,195) ;
INSERT INTO options values ( 811,'B. Create an HTTPS load balancer with URL maps.',TRUE,195) ;
INSERT INTO options values ( 812,'C. Create appropriate instance groups and instances. Configure SSL proxy load balancing. ',FALSE,195) ;
INSERT INTO options values ( 813,'D. Create a global forwarding rule. Configure SSL proxy balancing.',FALSE,195) ;
INSERT INTO options values ( 814,'A. Use gRPC instead of HTTP for better performance.',FALSE,196) ;
INSERT INTO options values ( 815,'B. Implement retry logic using a truncated exponential backoff strategy.',TRUE,196) ;
INSERT INTO options values ( 816,'C. Make sure the Cloud Storage bucket is multi-regional for geo-redundancy.',FALSE,196) ;
INSERT INTO options values ( 817,'D. Monitor https://status.cloud.google.com/feed.atom and only make requests if Cloud Storage is not reporting an incident.',FALSE,196) ;
INSERT INTO options values ( 818,'A. Use Deployment Manager to automate service provisioning. Use Activity Logs to monitor and debug your tests.',FALSE,197) ;
INSERT INTO options values ( 819,'B. Use Deployment Manager to automate provisioning. Use Stackdriver to monitor and debug your tests.',TRUE,197) ;
INSERT INTO options values ( 820,'C. Use gcloud scripts to automate service provisioning. Use Activity Logs monitor and debug your tests.',FALSE,197) ;
INSERT INTO options values ( 821,'D. Use automated scripts to automate service provisioning. Use Activity Logs monitor and debug your tests.',FALSE,197) ;
INSERT INTO options values ( 822,'A. Save the files in a Multi-Regional Cloud Storage bucket.',TRUE,198) ;
INSERT INTO options values ( 823,'B. Save the files in a Regional Cloud Storage bucket, one bucket per zone of the region.',FALSE,198) ;
INSERT INTO options values ( 824,'C. Save the files in multiple Regional Cloud Storage buckets, one bucket per zone per region.',FALSE,198) ;
INSERT INTO options values ( 825,'D. Save the files in multiple Multi-Regional Cloud Storage buckets, one bucket per multi-region.',FALSE,198) ;
INSERT INTO options values ( 826,'A. Store the data in Google Drive and manually delete records as they expire.',FALSE,199) ;
INSERT INTO options values ( 827,'B. Anonymize the data using the Cloud Data Loss Prevention API and store it indefinitely.',FALSE,199) ;
INSERT INTO options values ( 828,'C. Store the data using the Cloud Storage and use lifecycle management to delete files when they expire.',TRUE,199) ;
INSERT INTO options values ( 829,'D. Store the data in Cloud Storage and run a nightly batch script that deletes all expired data.',FALSE,199) ;
INSERT INTO options values ( 830,'A. Set the memcache service level to dedicated. Create a key from the hash of the query, and return database values from memcache before issuing a query to Cloud SQL.',TRUE,200) ;
INSERT INTO options values ( 831,'B. Set the memcache service level to dedicated. Create a cron task that runs every minute to populate the cache with keys containing query results.',FALSE,200) ;
INSERT INTO options values ( 832,'C. Set the memcache service level to shared. Create a cron task that runs every minute to save all expected queries to a key called “cached-queries”.',FALSE,200) ;
INSERT INTO options values ( 833,'D. Set the memcache service level to shared. Create a key called “cached-queries”, and return database values from the key before using a query to Cloud SQL.',FALSE,200) ;
INSERT INTO options values ( 834,'A. Using the Cron service provided by App Engine, publishing messages directly to a message-processing utility service running on Compute Engine instances.',FALSE,201) ;
INSERT INTO options values ( 835,'B. Using the Cron service provided by App Engine, publish messages to a Cloud Pub/Sub topic. Subscribe to that topic using a message-processing utility service running on Compute Engine instances.',TRUE,201) ;
INSERT INTO options values ( 836,'C. Using the Cron service provided by Google Kubernetes Engine (GKE), publish messages directly to a message-processing utility service running on Compute Engine instances.',FALSE,201) ;
INSERT INTO options values ( 837,'D. Using the Cron service provided by GKE, publish messages to a Cloud Pub/Sub topic. Subscribe to that topic using a message-processing utility service running on Compute Engine instances.',FALSE,201) ;
INSERT INTO options values ( 838,'A. Compress and upload both achieved files and files uploaded daily using the qsutil –m option. ',FALSE,202) ;
INSERT INTO options values ( 839,'B. Lease a Transfer Appliance, upload archived files to it, and send it, and send it to Google to transfer archived data to Cloud Storage. Establish a connection with Google using a Dedicated Interconnect or Direct Peering connection and use it to upload files daily.',TRUE,202) ;
INSERT INTO options values ( 840,'C. Lease a Transfer Appliance, upload archived files to it, and send it, and send it to Google to transfer archived data to Cloud Storage. Establish one Cloud VPN Tunnel to VPC networks over the public internet, and compares and upload files daily using the gsutil –m option.',FALSE,202) ;
INSERT INTO options values ( 841,'D. Lease a Transfer Appliance, upload archived files to it, and send it to Google to transfer archived data to Cloud Storage. Establish a Cloud VPN Tunnel to VPC networks over the public internet, and compress and upload files daily.',FALSE,202) ;
INSERT INTO options values ( 842,'A. Cloud Pub/Sub alone',FALSE,203) ;
INSERT INTO options values ( 843,'B. Cloud Pub/Sub to Cloud DataFlow ',TRUE,203) ;
INSERT INTO options values ( 844,'C. Cloud Pub/Sub to Stackdriver',FALSE,203) ;
INSERT INTO options values ( 845,'D. Cloud Pub/Sub to Cloud SQL',FALSE,203) ;
INSERT INTO options values ( 846,'A.1.Define a migration plan based on the list of the applications and their dependencies.2.Migrate all virtual machines into Compute Engine individually with Migrate for Compute Engine. ',FALSE,204) ;
INSERT INTO options values ( 847,'B.1.Perform an assessment of virtual machines running in the current VMware environment. 2.Create images of all disks. Import disks on Compute Engine.3.Create standard virtual machines where the boot disks are the ones you have imported.',FALSE,204) ;
INSERT INTO options values ( 848,'C.1.Perform an assessment of virtual machines running in the current VMware environment. 2.Define a migration plan, prepare a Migrate for Compute Engine migration RunBook, and execute the migration.',TRUE,204) ;
INSERT INTO options values ( 849,'D.1.Perform an assessment of virtual machines running in the current VMware environment. 2.Install a third-party agent on all selected virtual machines.3.Migrate all virtual machines into Compute Engine.',FALSE,204) ;
INSERT INTO options values ( 850,'A.Use a managed instance group with instances in multiple zones, use Cloud Filestore, and use an HTTP load balancer in front of the instances.',FALSE,205) ;
INSERT INTO options values ( 851,'B.Use a managed instance group with instances in multiple zones, use Cloud Filestore, and use a network load balancer in front of the instances.',FALSE,205) ;
INSERT INTO options values ( 852,'C.Use an unmanaged instance group with an active and standby instance in different zones, use a regional persistent disk, and use an HTTP load balancer in front of the instances.',FALSE,205) ;
INSERT INTO options values ( 853,'D.Use an unmanaged instance group with an active and standby instance in different zones, use a regional persistent disk, and use a network load balancer in front of the instances.',TRUE,205) ;
INSERT INTO options values ( 854,'A.Use OpenVPN to configure a VPN tunnel between the on-premises environment and Google Cloud.',FALSE,206) ;
INSERT INTO options values ( 855,'B.Configure a direct peering connection between the on-premises environment and Google Cloud.',FALSE,206) ;
INSERT INTO options values ( 856,'C.Use Cloud VPN to configure a VPN tunnel between the on-premises environment and Google Cloud.',FALSE,206) ;
INSERT INTO options values ( 857,'D.Configure a Cloud Dedicated Interconnect connection between the on-premises environment and Google Cloud.',TRUE,206) ;
INSERT INTO options values ( 858,'A.Deploy a new revision to Cloud Run with the new version. Configure traffic percentage between revisions.',TRUE,207) ;
INSERT INTO options values ( 859,'B.Deploy a new service to Cloud Run with the new version. Add a Cloud Load Balancing instance in front of both services.',FALSE,207) ;
INSERT INTO options values ( 860,'C.In the Google Cloud Console page for Cloud Run, set up continuous deployment using Cloud Build for the development branch. As part of the Cloud Build trigger, configure the substitution variable TRAFFIC_PERCENTAGE with the percentage of traffic you want directed to a new version.',FALSE,207) ;
INSERT INTO options values ( 861,'D.In the Google Cloud Console, configure Traffic Director with a new Service that points to the new version of the application on Cloud Run. Configure Traffic Director to send a small percentage of traffic to the new version of the application.',FALSE,207) ;
INSERT INTO options values ( 862,'A.Navigate the predefined dashboards in the Cloud Monitoring workspace, and then add metrics and create alert policies.',TRUE,208) ;
INSERT INTO options values ( 863,'B.Navigate the predefined dashboards in the Cloud Monitoring workspace, create custom metrics, and install alerting software on a Compute Engine instance.',FALSE,208) ;
INSERT INTO options values ( 864,'C.Write a shell script that gathers metrics from GKE nodes, publish these metrics to a Pub/Sub topic, export the data to BigQuery, and make a Data Studio dashboard.',FALSE,208) ;
INSERT INTO options values ( 865,'D.Create a custom dashboard in the Cloud Monitoring workspace for each incident, and then add metrics and create alert policies.',FALSE,208) ;
INSERT INTO options values ( 866,'A.Sharding',FALSE,209) ;
INSERT INTO options values ( 867,'B.Read replicas ',FALSE,209) ;
INSERT INTO options values ( 868,'C.Binary logging',TRUE,209) ;
INSERT INTO options values ( 869,'D.Automated backups',TRUE,209) ;
INSERT INTO options values ( 870,'E.Semisynchronous replication',FALSE,209) ;
INSERT INTO options values ( 871,'A.Use a unique identifier for each individual. Upon a deletion request, delete all rows from BigQuery with this identifier.',FALSE,210) ;
INSERT INTO options values ( 872,'B.When ingesting new data in BigQuery, run the data through the Data Loss Prevention (DLP) API to identify any personal information. As part of the DLP scan, save the result to Data Catalog. Upon a deletion request, query Data Catalog to find the column with personal information.',TRUE,210) ;
INSERT INTO options values ( 873,'C.Create a BigQuery view over the table that contains all data. Upon a deletion request, exclude the rows that affect the subject’s data from this view. Use this view instead of the source table for all analysis tasks.',FALSE,210) ;
INSERT INTO options values ( 874,'D.Use a unique identifier for each individual. Upon a deletion request, overwrite the column with the unique identifier with a salted SHA256 of its value.',FALSE,210) ;
INSERT INTO options values ( 875,'A.App Engine ',TRUE,211) ;
INSERT INTO options values ( 876,'B.GKE On-Prem',FALSE,211) ;
INSERT INTO options values ( 877,'C.Compute Engine',FALSE,211) ;
INSERT INTO options values ( 878,'D.Google Kubernetes Engine',FALSE,211) ;
INSERT INTO options values ( 879,'A.Create a shell script that uses the gcloud command to change the machine type of the development and acceptance instances to a smaller machine type outside of ofice hours. Schedule the shell script on one of the production instances to automate the task.',FALSE,212) ;
INSERT INTO options values ( 880,'B.Use Cloud Scheduler to trigger a Cloud Function that will stop the development and acceptance environments after ofice hours and start them just before ofice hours.',TRUE,212) ;
INSERT INTO options values ( 881,'C.Deploy the development and acceptance applications on a managed instance group and enable autoscaling.',FALSE,212) ;
INSERT INTO options values ( 882,'D.Use regular Compute Engine instances for the production environment, and use preemptible VMs for the acceptance and development environments.',FALSE,212) ;
INSERT INTO options values ( 883,'A.1. Set up Cloud VPN to provide private network connectivity between the Compute Engine application and the on-premises MySQL server.2.Stop the on-premises application.3.Create a mysqldump of the on-premises MySQL server.4.Upload the dump to a Cloud Storage bucket.5.Import the dump into Cloud SQL.6.Modify the source code of the application to write queries to both databases and read from its local database.7.Start the Compute Engine application.8.Stop the on-premises application.',FALSE,213) ;
INSERT INTO options values ( 884,'B.1. Set up Cloud SQL proxy and MySQL proxy.2.Create a mysqldump of the on-premises MySQL server. 3.Upload the dump to a Cloud Storage bucket.4.     Import the dump into Cloud SQL. 5.Stop the on-premises application. 6.Start the Compute Engine application.',FALSE,213) ;
INSERT INTO options values ( 885,'C.1. Set up Cloud VPN to provide private network connectivity between the Compute Engine application and the on-premises MySQL server. 2.Stop the on-premises application. 3.Start the Compute Engine application, configured to read and write to the on-premises MySQL server. 4.Create the replication configuration in Cloud SQL. 5.Configure the source database server to accept connections from the Cloud SQL replica. 6.Finalize the Cloud SQL replica configuration. 7.When replication has been completed, stop the Compute Engine application. 8.Promote the Cloud SQL replica to a standalone instance. 9.Restart the Compute Engine application, configured to read and write to the Cloud SQL standalone instance.',TRUE,213) ;
INSERT INTO options values ( 886,'D.1. Stop the on-premises application. 2.Create a mysqldump of the on-premises MySQL server. 3.Upload the dump to a Cloud Storage bucket. 4.Import the dump into Cloud SQL. 5.Start the application on Compute Engine. ',FALSE,213) ;
INSERT INTO options values ( 887,'A.Remove the default route on all VPCs. Move all approved instances into a new subnet that has a default route to an internet gateway.',FALSE,214) ;
INSERT INTO options values ( 888,'B.Create a new VPC in custom mode. Create a new subnet for the approved instances, and set a default route to the internet gateway on this new subnet.',FALSE,214) ;
INSERT INTO options values ( 889,'C.Implement a Cloud NAT solution to remove the need for external IP addresses entirely.',FALSE,214) ;
INSERT INTO options values ( 890,'D.Set an Organization Policy with a constraint on constraints/compute.vmExternalIpAccess. List the approved instances in the allowedValues list.',TRUE,214) ;
INSERT INTO options values ( 891,'A.Enable Virtual Private Cloud (VPC) flow logging.',FALSE,215) ;
INSERT INTO options values ( 892,'B.Enable Firewall Rules Logging for the firewall rules you want to monitor.',TRUE,215) ;
INSERT INTO options values ( 893,'C.Verify that your user account is assigned the compute.networkAdmin Identity and Access Management (IAM) role.',FALSE,215) ;
INSERT INTO options values ( 894,'D.Install the Google Cloud SDK, and verify that there are no Firewall logs in the command line',FALSE,215) ;
INSERT INTO options values ( 895,'A.1. Create a VPC Service Controls perimeter that includes the projects with the buckets. 2. Create an access level with the CIDR of the office network.',TRUE,216) ;
INSERT INTO options values ( 896,'B.1. Create a firewall rule for all instances in the Virtual Private Cloud (VPC) network for source range. 2. Use the Classless Inter-domain Routing (CIDR) of the ofice network.',FALSE,216) ;
INSERT INTO options values ( 897,'C.1. Create a Cloud Function to remove IAM permissions from the buckets, and another Cloud Function to add IAM permissions to the buckets. 2. Schedule the Cloud Functions with Cloud Scheduler to add permissions at the start of business and remove permissions at the end of business. ',FALSE,216) ;
INSERT INTO options values ( 898,'D.1. Create a Cloud VPN to the ofice network. 2. Configure Private Google Access for on-premises hosts.',FALSE,216) ;
INSERT INTO options values ( 899,'A.Start a new rolling restart operation. ',FALSE,217) ;
INSERT INTO options values ( 900,'B.Start a new rolling replace operation.',FALSE,217) ;
INSERT INTO options values ( 901,'C.Start a new rolling update. Select the Proactive update mode.',FALSE,217) ;
INSERT INTO options values ( 902,'D.Start a new rolling update. Select the Opportunistic update mode.',TRUE,217) ;
INSERT INTO options values ( 903,'A.Create a snapshot schedule for the disk containing the application data. Whenever a zonal outage occurs, use the latest snapshot to restore the disk in the same zone.',FALSE,218) ;
INSERT INTO options values ( 904,'B.Configure the Compute Engine instances with an instance template for the application, and use a regional persistent disk for the application data. Whenever a zonal outage occurs, use the instance template to spin up the application in another zone in the same region. Use the regional persistent disk for the application data.',TRUE,218) ;
INSERT INTO options values ( 905,'C.Create a snapshot schedule for the disk containing the application data. Whenever a zonal outage occurs, use the latest snapshot to restore the disk in another zone within the same region. ',FALSE,218) ;
INSERT INTO options values ( 906,'D.Configure the Compute Engine instances with an instance template for the application, and use a regional persistent disk for the application data. Whenever a zonal outage occurs, use the instance template to spin up the application in another region. Use the regional persistent disk for the application data.',FALSE,218) ;
INSERT INTO options values ( 907,'A.Create a Cloud VPN connection from the new VPC to the data center, create a Cloud Router, and apply new IP addresses so there is no overlapping IP space.',TRUE,219) ;
INSERT INTO options values ( 908,'B.Create a Cloud VPN connection from the new VPC to the data center, and create a Cloud NAT instance to perform NAT on the overlapping IP space.',FALSE,219) ;
INSERT INTO options values ( 909,'C.Create a Cloud VPN connection from the new VPC to the data center, create a Cloud Router, and apply a custom route advertisement to block the overlapping IP space.',FALSE,219) ;
INSERT INTO options values ( 910,'D.Create a Cloud VPN connection from the new VPC to the data center, and apply a firewall rule that blocks the overlapping IP space.',FALSE,219) ;
INSERT INTO options values ( 911,'A.Create a Dataproc cluster using standard worker instances.',FALSE,220) ;
INSERT INTO options values ( 912,'B.Create a Dataproc cluster using preemptible worker instances.',TRUE,220) ;
INSERT INTO options values ( 913,'C.Manually deploy a Hadoop cluster on Compute Engine using standard instances.',FALSE,220) ;
INSERT INTO options values ( 914,'D.Manually deploy a Hadoop cluster on Compute Engine using preemptible instances.',FALSE,220) ;
INSERT INTO options values ( 915,'A.Create a cloud router to advertise subnet #2 and subnet #3 to subnet #1. ',FALSE,221) ;
INSERT INTO options values ( 916,'B.Add two additional NICs to Instance #1 with the following configuration: •NIC1 ○VPC: VPC #2 ○SUBNETWORK: subnet #2 •NIC2 ○VPC: VPC #3 ○SUBNETWORK: subnet #3 Update firewall rules to enable traffic between instances. ',TRUE,221) ;
INSERT INTO options values ( 917,'C.Create two VPN tunnels via CloudVPN: •1 between VPC #1 and VPC #2. •1 between VPC #2 and VPC #3.Update firewall rules to enable traffic between the instances. ',FALSE,221) ;
INSERT INTO options values ( 918,'D.Peer all three VPCs:•Peer VPC #1 with VPC #2. •Peer VPC #2 with VPC #3.Update firewall rules to enable traffic between the instances.',FALSE,221) ;
INSERT INTO options values ( 919,'A.Create a Compute Engine instance template using the most recent Debian image. Create an instance from this template, and install and configure the application as part of the startup script. Repeat this process whenever a new Google-managed Debian image becomes available.',FALSE,222) ;
INSERT INTO options values ( 920,'B.Create a Debian-based Compute Engine instance, install and configure the application, and use OS patch management to install available updates.',TRUE,222) ;
INSERT INTO options values ( 921,'C.Create an instance with the latest available Debian image. Connect to the instance via SSH, and install and configure the application on the instance. Repeat this process whenever a new Google-managed Debian image becomes available.',FALSE,222) ;
INSERT INTO options values ( 922,'D.Create a Docker container with Debian as the base image. Install and configure the application as part of the Docker image creation process. Host the container on Google Kubernetes Engine and restart the container whenever a new update is available.',FALSE,222) ;
INSERT INTO options values ( 923,'A.1.Update your GKE cluster to use Cloud Operations for GKE. 2.Use the GKE Monitoring dashboard to investigate logs from affected Pods. ',TRUE,223) ;
INSERT INTO options values ( 924,'B.1.Create a new GKE cluster with Cloud Operations for GKE enabled. 2.Migrate the affected Pods to the new cluster, and redirect traffic for those Pods to the new cluster. 3.Use the GKE Monitoring dashboard to investigate logs from affected Pods.',FALSE,223) ;
INSERT INTO options values ( 925,'C.1.Update your GKE cluster to use Cloud Operations for GKE, and deploy Prometheus. 2.Set an alert to trigger whenever the application returns an error.',FALSE,223) ;
INSERT INTO options values ( 926,'D.1.Create a new GKE cluster with Cloud Operations for GKE enabled, and deploy Prometheus. 2.Migrate the affected Pods to the new cluster, and redirect traffic for those Pods to the new cluster. 3.Set an alert to trigger whenever the application returns an error.',FALSE,223) ;
INSERT INTO options values ( 927,'A.Use a persistent disk for each instance.',FALSE,224) ;
INSERT INTO options values ( 928,'B.Use a regional persistent disk for each instance.',FALSE,224) ;
INSERT INTO options values ( 929,'C.Create a Cloud Filestore instance and mount it in each instance.',TRUE,224) ;
INSERT INTO options values ( 930,'D.Create a Cloud Storage bucket and mount it in each instance using gcsfuse.',FALSE,224) ;
INSERT INTO options values ( 931,'A.Use the Service Mesh visualization in the Cloud Console to inspect the telemetry between the microservices.',TRUE,225) ;
INSERT INTO options values ( 932,'B.Use Anthos Config Management to create a ClusterSelector selecting the relevant cluster. On the Google Cloud Console page for Google Kubernetes Engine, view the Workloads and filter on the cluster. Inspect the configurations of the filtered workloads.',FALSE,225) ;
INSERT INTO options values ( 933,'C.Use Anthos Config Management to create a namespaceSelector selecting the relevant cluster namespace. On the Google Cloud Console page for Google Kubernetes Engine, visit the workloads and filter on the namespace. Inspect the configurations of the filtered workloads.',FALSE,225) ;
INSERT INTO options values ( 934,'D.Reinstall istio using the default istio profile in order to collect request latency. Evaluate the telemetry between the microservices in the Cloud Console.',FALSE,225) ;
INSERT INTO options values ( 935,'A.Create a retention policy on the bucket for the duration of 5 years. Create a lock on the retention policy.',TRUE,226) ;
INSERT INTO options values ( 936,'B.Create the bucket with uniform bucket-level access, and grant a service account the role of Object Writer. Use the service account to upload new files.',FALSE,226) ;
INSERT INTO options values ( 937,'C.Use a customer-managed key for the encryption of the bucket. Rotate the key after 5 years. ',FALSE,226) ;
INSERT INTO options values ( 938,'D.Create the bucket with fine-grained access control, and grant a service account the role of Object Writer. Use the service account to upload new files.',FALSE,226) ;
INSERT INTO options values ( 939,'A.Have each developer install a pre-commit hook on their workstation that tests the code and builds the container when commiting on the development branch. After a successful commit, have the developer deploy the newly built container image on the development cluster.',FALSE,227) ;
INSERT INTO options values ( 940,'B.Install a post-commit hook on the remote git repository that tests the code and builds the container when code is pushed to the development branch. After a successful commit, have the developer deploy the newly built container image on the development cluster.',FALSE,227) ;
INSERT INTO options values ( 941,'C.Create a Cloud Build trigger based on the development branch that tests the code, builds the',TRUE,227) ;
INSERT INTO options values ( 942,'D.Create a Cloud Build trigger based on the development branch to build a new container image and store it in Container Registry. Rely on Vulnerability Scanning to ensure the code tests succeed. As the final step of the Cloud Build process, deploy the new container image on the development cluster. Ensure only Cloud Build has access to deploy new versions.',FALSE,227) ;
INSERT INTO options values ( 943,'A.Change the autoscaling metric to agent.googleapis.com/memory/percent_used. ',FALSE,228) ;
INSERT INTO options values ( 944,'B.Restart the affected instances on a staggered schedule.',FALSE,228) ;
INSERT INTO options values ( 945,'C.SSH to each instance and restart the application process.',FALSE,228) ;
INSERT INTO options values ( 946,'D.Increase the maximum number of instances in the autoscaling group.',TRUE,228) ;
INSERT INTO options values ( 947,'A.Cloud Run and BigQuery',FALSE,229) ;
INSERT INTO options values ( 948,'B.Cloud Run and Cloud Bigtable',TRUE,229) ;
INSERT INTO options values ( 949,'C.A Compute Engine autoscaling managed instance group and BigQuery',FALSE,229) ;
INSERT INTO options values ( 950,'D.A Compute Engine autoscaling managed instance group and Cloud Bigtable',FALSE,229) ;
INSERT INTO options values ( 951,'A.Deploy each microservice as a Deployment. Expose the Deployment in the cluster using a Service, and use the Service DNS name to address it from other microservices within the cluster.',TRUE,230) ;
INSERT INTO options values ( 952,'B.Deploy each microservice as a Deployment. Expose the Deployment in the cluster using an Ingress, and use the Ingress IP address to address the Deployment from other microservices within the cluster.',FALSE,230) ;
INSERT INTO options values ( 953,'C.Deploy each microservice as a Pod. Expose the Pod in the cluster using a Service, and use the Service DNS name to address the microservice from other microservices within the cluster.',FALSE,230) ;
INSERT INTO options values ( 954,'D.Deploy each microservice as a Pod. Expose the Pod in the cluster using an Ingress, and use the Ingress IP address name to address the Pod from other microservices within the cluster.',FALSE,230) ;
INSERT INTO options values ( 955,'A.1. Create a project with a standalone VPC and assign the Network Admin role to the networking team.2.Create a second project with a standalone VPC and assign the Compute Admin role to the development team.3.Use Cloud VPN to join the two VPCs.',FALSE,231) ;
INSERT INTO options values ( 956,'B.1. Create a project with a standalone Virtual Private Cloud (VPC), assign the Network Admin role to the networking team, and assign the Compute Admin role to the development team.',FALSE,231) ;
INSERT INTO options values ( 957,'C.1. Create a project with a Shared VPC and assign the Network Admin role to the networking team.2. Create a second project without a VPC, configure it as a Shared VPC service project, and assign the Compute Admin role to the development team.',TRUE,231) ;
INSERT INTO options values ( 958,'D.1. Create a project with a standalone VPC and assign the Network Admin role to the networking team.2.Create a second project with a standalone VPC and assign the Compute Admin role to the development team.3.Use VPC Peering to join the two VPCs.',FALSE,231) ;
INSERT INTO options values ( 959,'A.Store static content such as HTML and images in Cloud CDN. Host the APIs on App Engine and store the user data in Cloud SQL.',FALSE,232) ;
INSERT INTO options values ( 960,'B.Store static content such as HTML and images in a Cloud Storage bucket. Host the APIs on a zonal Google Kubernetes Engine cluster with worker nodes in multiple zones, and save the user data in Cloud Spanner.',FALSE,232) ;
INSERT INTO options values ( 961,'C.Store static content such as HTML and images in Cloud CDN. Use Cloud Run to host the APIs and save the user data in Cloud SQL.',FALSE,232) ;
INSERT INTO options values ( 962,'D.Store static content such as HTML and images in a Cloud Storage bucket. Use Cloud Functions to host the APIs and save the user data in Firestore',TRUE,232) ;
INSERT INTO options values ( 963,'A.Schedule a cron job with Cloud Scheduler. The scheduled job queries the logs every minute for the relevant events.',FALSE,233) ;
INSERT INTO options values ( 964,'B.Export logs to BigQuery, and trigger a query in BigQuery to process the log data for the relevant events.',FALSE,233) ;
INSERT INTO options values ( 965,'C.Export logs to a Pub/Sub topic, and trigger Cloud Function with the relevant log events. ',TRUE,233) ;
INSERT INTO options values ( 966,'D.Export logs to a Cloud Storage bucket, and trigger Cloud Run with the relevant log events.',FALSE,233) ;
INSERT INTO options values ( 967,'A.Configure Cloud NAT on the subnet where the instance is hosted. Create an SSH connection to the Cloud NAT IP address to reach the instance.',FALSE,234) ;
INSERT INTO options values ( 968,'B.Add all instances to an unmanaged instance group. Configure TCP Proxy Load Balancing with the instance group as a backend. Connect to the instance using the TCP Proxy IP.',FALSE,234) ;
INSERT INTO options values ( 969,'C.Configure Identity-Aware Proxy (IAP) for the instance and ensure that you have the role of IAP-secured Tunnel User. Use the gcloud command line tool to ssh into the instance.',TRUE,234) ;
INSERT INTO options values ( 970,'D.Create a bastion host in the network to SSH into the bastion host from your ofice location. From the bastion host, SSH into the desired instance.',FALSE,234) ;
INSERT INTO options values ( 971,'A.Assign the development team group the Project Viewer role on the Finance folder, and assign the development team group the Project Owner role on the Shopping folder.',FALSE,235) ;
INSERT INTO options values ( 972,'B.Assign the development team group only the Project Viewer role on the Finance folder. ',FALSE,235) ;
INSERT INTO options values ( 973,'C.Assign the development team group the Project Owner role on the Shopping folder, and remove the development team group Project Owner role from the Organization.',TRUE,235) ;
INSERT INTO options values ( 974,'D.Assign the development team group only the Project Owner role on the Shopping folder',FALSE,235) ;
INSERT INTO options values ( 975,'A.Add a taint to one of the nodes of the Kubernetes cluster. For the specific microservice, configure a pod anti-afinity label that has the name of the tainted node as a value.',FALSE,236) ;
INSERT INTO options values ( 976,'B.Use Istio’s fault injection on the particular microservice whose faulty behavior you want to simulate.',TRUE,236) ;
INSERT INTO options values ( 977,'C.Destroy one of the nodes of the Kubernetes cluster to observe the behavior.',FALSE,236) ;
INSERT INTO options values ( 978,'D.Configure Istio’s traffic management features to steer the traffic away from a crashing microservice.',FALSE,236) ;
INSERT INTO options values ( 979,'A.App Engine',TRUE,237) ;
INSERT INTO options values ( 980,'B.Cloud Endpoints ',FALSE,237) ;
INSERT INTO options values ( 981,'C.Compute Engine',FALSE,237) ;
INSERT INTO options values ( 982,'D.Google Kubernetes Engine',FALSE,237) ;
INSERT INTO options values ( 983,'A.Create a distribution list of all customers to inform them of an upcoming backward-incompatible change at least one month before replacing the old API with the new API.',FALSE,238) ;
INSERT INTO options values ( 984,'B.Create an automated process to generate API documentation, and update the public API documentation as part of the CI/CD process when deploying an update to the API.',FALSE,238) ;
INSERT INTO options values ( 985,'C.Use a versioning strategy for the APIs that increases the version number on every backward-incompatible change.',TRUE,238) ;
INSERT INTO options values ( 986,'D.Use a versioning strategy for the APIs that adds the sufix “DEPRECATED” to the current API version number on every backward-incompatible change. Use the current version number for the new API.',FALSE,238) ;
INSERT INTO options values ( 987,'A.The new approach will be significantly less costly, make it easier to manage the underlying infrastructure, and automatically manage the CI/CD pipelines.',FALSE,239) ;
INSERT INTO options values ( 988,'B.The monolithic solution can be converted to a container with Docker. The generated container can then be deployed into a Kubernetes cluster.',FALSE,239) ;
INSERT INTO options values ( 989,'C.The new approach will make it easier to decouple infrastructure from application, develop and release new features, manage the underlying infrastructure, manage CI/CD pipelines and perform A/B testing, and scale the solution if necessary.',TRUE,239) ;
INSERT INTO options values ( 990,'D.The process can be automated with Migrate for Compute Engine.',FALSE,239) ;
INSERT INTO options values ( 991,'A.Use a load testing tool to simulate the expected number of concurrent users and total requests to your application, and inspect the results.',TRUE,240) ;
INSERT INTO options values ( 992,'B.Enable autoscaling on the GKE cluster and enable horizontal pod autoscaling on your application deployments. Send curl requests to your application, and validate if the auto scaling works.',FALSE,240) ;
INSERT INTO options values ( 993,'C.Replicate the application over multiple GKE clusters in every Google Cloud region. Configure a global HTTP(S) load balancer to expose the different clusters over a single global IP address.',FALSE,240) ;
INSERT INTO options values ( 994,'D.Use Cloud Debugger in the development environment to understand the latency between the different microservices.',FALSE,240) ;
INSERT INTO options values ( 995,'A. Use a Managed Instance Group when deploying to Compute Engine',FALSE,241) ;
INSERT INTO options values ( 996,'B. Develop an application with containers, and deploy to Google Kubernetes Engine (GKE) ',FALSE,241) ;
INSERT INTO options values ( 997,'C. Develop the application for App Engine standard environment',TRUE,241) ;
INSERT INTO options values ( 998,'D. Develop the application for App Engine Flexible environment using a custom runtime',FALSE,241) ;
INSERT INTO options values ( 999,'A. Add the node group name as a network tag when creating Compute Engine instances in order to host each workload on the correct node group.',FALSE,242) ;
INSERT INTO options values ( 1000,'B. Add the node name as a network tag when creating Compute Engine instances in order to host each workload on the correct node.',FALSE,242) ;
INSERT INTO options values ( 1001,'C. Use node affinity labels based on the node group name when creating Compute Engine instances in order to host each workload on the correct node group',FALSE,242) ;
INSERT INTO options values ( 1002,'D. Use node affinity labels based on the node name when creating Compute Engine instances in order to host each workload on the correct node.',TRUE,242) ;
INSERT INTO options values ( 1003,'A. Configure Private Google Access for on-premises only.',FALSE,243) ;
INSERT INTO options values ( 1004,'B. Perform the following tasks: 1) Create a service account.2) Give the BigQuery JobUser role and Storage Reader role to the service account. 3) Remove all other IAM access from the project.',FALSE,243) ;
INSERT INTO options values ( 1005,'C. Configure VPC Service Controls and configure Private Google Access.',TRUE,243) ;
INSERT INTO options values ( 1006,'D. Configure Private Google Access.',FALSE,243) ;
INSERT INTO options values ( 1007,'A. Send the data through the processing pipeline, and then store the processed data in a BigQuery table for reprocessing.',FALSE,244) ;
INSERT INTO options values ( 1008,'B. Store the data in a BigQuery table. Design the processing pipelines to retrieve the data from the table.',FALSE,244) ;
INSERT INTO options values ( 1009,'C. Send the data through the processing pipeline, and then store the processed data in a Cloud Storage bucket for reprocessing.',FALSE,244) ;
INSERT INTO options values ( 1010,'D. Store the data in a Cloud Storage bucket. Design the processing pipelines to retrieve the data from the bucket',TRUE,244) ;
INSERT INTO options values ( 1011,'A. Make sure a developer is tagging the code commit with the date and time of commit',FALSE,245) ;
INSERT INTO options values ( 1012,'B. Make sure a developer is adding a comment to the commit that links to the deployment. ',FALSE,245) ;
INSERT INTO options values ( 1013,'C. Make the container tag match the source code commit hash.',TRUE,245) ;
INSERT INTO options values ( 1014,'D. Make sure the developer is tagging the commits with :latest',FALSE,245) ;
INSERT INTO options values ( 1015,'A. Create a key with Cloud Key Management Service (KMS) Encrypt the data using the encrypt method of Cloud KMS.',FALSE,246) ;
INSERT INTO options values ( 1016,'B. Create a key with Cloud Key Management Service (KMS). Set the encryption key on the bucket to the Cloud KMS key.',TRUE,246) ;
INSERT INTO options values ( 1017,'C. Generate a GPG key pair. Encrypt the data using the GPG key. Upload the encrypted data to the bucket.',FALSE,246) ;
INSERT INTO options values ( 1018,'D. Generate an AES-256 encryption key. Encrypt the data in the bucket using the customer-supplied encryption keys feature.',FALSE,246) ;
INSERT INTO options values ( 1019,'A.Generate a new key in Cloud Key Management Service (Cloud KMS). Store all data in Cloud Storage using the customer-managed key option and select the created key. Set up a Dataflow pipeline to decrypt the data and to store it in a BigQuery dataset.',FALSE,247) ;
INSERT INTO options values ( 1020,'B.Generate a new key in Cloud Key Management Service (Cloud KMS). Create a dataset in BigQuery using the customer-managed key option and select the created key',FALSE,247) ;
INSERT INTO options values ( 1021,'C.Import a key in Cloud KMS. Store all data in Cloud Storage using the customer-managed key option and select the created key. Set up a Dataflow pipeline to decrypt the data and to store it in a new BigQuery dataset.',FALSE,247) ;
INSERT INTO options values ( 1022,'D.Import a key in Cloud KMS. Create a dataset in BigQuery using the customer-supplied key option and select the created key.',TRUE,247) ;
INSERT INTO options values ( 1023,'A.Configure private services access',FALSE,248) ;
INSERT INTO options values ( 1024,'B.Configure private Google access for on-premises hosts only ',FALSE,248) ;
INSERT INTO options values ( 1025,'C.Configure serverless VPC access',TRUE,248) ;
INSERT INTO options values ( 1026,'D.Configure private Google access',FALSE,248) ;
INSERT INTO options values ( 1027,'A.Enable the Cloud Trace API on your project and use Cloud Monitoring Alerts to send an alert based on the Cloud Trace metrics',FALSE,249) ;
INSERT INTO options values ( 1028,'B.Configure Anthos Config Management on your cluster and create a yaml file that defines the SLO and alerting policy you want to deploy in your cluster',FALSE,249) ;
INSERT INTO options values ( 1029,'C.Use Cloud Profiler to follow up the request latency. Create a custom metric in Cloud Monitoring based on the results of Cloud Profiler, and create an Alerting Policy in case this metric exceeds the threshold',FALSE,249) ;
INSERT INTO options values ( 1030,'D.Install Anthos Service Mesh on your cluster. Use the Google Cloud Console to define a Service Level Objective (SLO)',TRUE,249) ;
INSERT INTO options values ( 1031,'A.Create a Compute engine instance with CPU and Memory options similar to your application’s current on-premises virtual machine. Install the cloud monitoring agent, and deploy the third party application. Run a load with normal traffic levels on third party application and follow the Rightsizing Recommendations in the Cloud Console',TRUE,250) ;
INSERT INTO options values ( 1032,'B.Create an App Engine flexible environment, and deploy the third party application using a Docker file and a custom runtime. Set CPU and memory options similar to your application’s current on-premises virtual machine in the app.yaml file.',FALSE,250) ;
INSERT INTO options values ( 1033,'C.Create an instance template with the smallest available machine type, and use an image of the third party application taken from the current on-premises virtual machine. Create a managed instance group that uses average CPU to autoscale the number of instances in the group. Modify the average CPU utilization threshold to optimize the number of instances running.',FALSE,250) ;
INSERT INTO options values ( 1034,'D.Create multiple Compute Engine instances with varying CPU and memory options. Install the cloud monitoring agent and deploy the third-party application on each of them. Run a load test with high traffic levels on the application and use the results to determine the optimal setings.',FALSE,250) ;
INSERT INTO options values ( 1035,'A.Use a global HTTP(s) load balancer with Cloud CDN enabled',FALSE,251) ;
INSERT INTO options values ( 1036,'B.Create a second GKE cluster in asia-southeast1, and expose both API’s using a Service of type Load Balancer. Add the public Ips to the Cloud DNS zone',FALSE,251) ;
INSERT INTO options values ( 1037,'C.Increase the memory and CPU allocated to the application in the cluster',FALSE,251) ;
INSERT INTO options values ( 1038,'D.Create a second GKE cluster in asia-southeast1, and use kubemci to create a global HTTP(s) load balancer',TRUE,251) ;
INSERT INTO options values ( 1039,'A.1) Use gsutil -m to upload all the files to Cloud Storage. 2) Use gsutil cp to download the uploaded files3) Use Linux diff to compare the content of the files',FALSE,252) ;
INSERT INTO options values ( 1040,'B.1) Use gsutil -m to upload all the files to Cloud Storage.2) Develop a custom Java application that computes CRC32C hashes3) Use gsutil ls -L gs://[YOUR_BUCKET_NAME] to collect CRC32C hashes of the uploaded files 4)Compare the hashes',FALSE,252) ;
INSERT INTO options values ( 1041,'C.1) Use Linux shasum to compute a digest of files you want to upload 2) Use gsutil -m to upload all the files to the Cloud Storage3) Use gsutil cp to download the uploaded files 4) Use Linux shasum to compute a digest of the downloaded files 5.Compre the hashes ',FALSE,252) ;
INSERT INTO options values ( 1042,'D.1)Use gsutil -m to upload all the files to Cloud Storage.2)Use gsutil hash -c FILE_NAME to generate CRC32C hashes of all on-premises files 3)Use gsutil ls -L gs://[YOUR_BUCKET_NAME] to collect CRC32C hashes of the uploaded files 4)Compare the hashes',TRUE,252) ;
INSERT INTO options values ( 1043,'A.Create a Kubernetes admission controller to prevent the container from starting if it is not approved for usage in the given environment',FALSE,253) ;
INSERT INTO options values ( 1044,'B.Configure a Kubernetes lifecycle hook to prevent the container from starting if it is not approved for usage in the given environment',FALSE,253) ;
INSERT INTO options values ( 1045,'C.Implement a corporate policy to prevent teams from deploying Docker image to an environment unless the Docker image was tested in an earlier environment',FALSE,253) ;
INSERT INTO options values ( 1046,'D.Configure the binary authorization policies for the development, staging and production clusters. Create attestations as part of the continuous integration pipeline”',TRUE,253) ;
INSERT INTO options values ( 1047,'A.Create a Compute Engine instance, and install a NAT Proxy on the instance. Configure all workloads on GKE to pass through this proxy to access third-party services on the Internet',FALSE,254) ;
INSERT INTO options values ( 1048,'B.Configure the GKE cluster as a private cluster, and configure Cloud NAT Gateway for the cluster subnet',TRUE,254) ;
INSERT INTO options values ( 1049,'C.Configure the GKE cluster as a route-based cluster. Configure Private Google Access on the Virtual Private Cloud (VPC)',FALSE,254) ;
INSERT INTO options values ( 1050,'D.Configure the GKE cluster as a private cluster. Configure Private Google Access on the Virtual Private Cloud (VPC)',FALSE,254) ;
INSERT INTO options values ( 1051,'A.Configure a Kubernetes autoscaling based on the subscription/push_request metric. ',FALSE,255) ;
INSERT INTO options values ( 1052,'B.Use the –enable- autoscaling flag when you create the Kubernetes cluster',FALSE,255) ;
INSERT INTO options values ( 1053,'C.Configure a Kubernetes autoscaling based on the subscription/num_undelivered message metric.',TRUE,255) ;
INSERT INTO options values ( 1054,'D.Use kubectl autoscale deployment APP_NAME –max 6 –min 2 –cpu- percent 50 to configure Kubernetes autoscaling deployment',FALSE,255) ;
INSERT INTO options values ( 1055,'A.1. Attach a persistent SSD disk to the first instance 2. Create a snapshot every hour 3. In case of a zone outage, recreate a persistent SSD disk in the second instance where data is coming from the created snapshot',FALSE,256) ;
INSERT INTO options values ( 1056,'B.1 Create a Cloud Storage bucket 2. Mount the bucket into the first instance with gcs-fuse 3. In case of a zone outage, mount the Cloud Storage bucket to the second instance with gcs-fuse ',FALSE,256) ;
INSERT INTO options values ( 1057,'C.1 Attach a local SSD lo the first instance disk 2. Execute an rsync command every hour where the target is a persistent SSD disk attached to the second instance 3. In case of a zone outage, use the second instance ',FALSE,256) ;
INSERT INTO options values ( 1058,'D.1. Attach a regional SSD persistent Ask to the first instance2. In case of a zone outage, force-attach the disk to the other instance',TRUE,256) ;
INSERT INTO options values ( 1059,'A.1. Copy popular songs into CloudSQL as a blob 2. Update application code to retrieve data from CloudSQL when Cloud Storage is overloaded ',FALSE,257) ;
INSERT INTO options values ( 1060,'B.1. Create a managed instance group with Compute Engine instances 2. Create a global toad balancer and configure ii with two backbends * Managed instance group * Cloud Storage bucket 3. Enable Cloud CDN on the bucket backend ',TRUE,257) ;
INSERT INTO options values ( 1061,'C.1. Mount the Cloud Storage bucket using gcsfuse on all backend Compute Engine instances 2. Serve muse files directly from the backend Compute Engine instance',FALSE,257) ;
INSERT INTO options values ( 1062,'D.1. Create a Cloud Filestore NFS volume and attach it to the backend Compute Engine instances 2. Download popular songs in Cloud Filestore 3. Serve music Wes directly from the backend Compute Engine instance',FALSE,257) ;
INSERT INTO options values ( 1063,'A. Set up a network peering between vpc-a and vpc-b',TRUE,258) ;
INSERT INTO options values ( 1064,'B. Set up a VPN between vpc-a and vpc-b using Cloud VPN',FALSE,258) ;
INSERT INTO options values ( 1065,'C. Configure IAP TCP forwarding on the instance in vpc b and then launch the following gcloud command from one of the instance in vpc-gcloud: 1. Create an additional instance in vpc-a 2. Create an additional instance in vpc-b 3. Instal OpenVPN in newly created 4. Configure a VPN tunnel between vpc-a and vpc-b with the help of OpenVPNinstances',FALSE,258) ;
INSERT INTO options values ( 1066,'A. Advise your clients to use HBase APIs instead of NodeJS APIs.',FALSE,259) ;
INSERT INTO options values ( 1067,'B. Review your RowKey strategy and ensure that keys are evenly spread across the alphabet. ',TRUE,259) ;
INSERT INTO options values ( 1068,'C. Delete records older than 30 days.',FALSE,259) ;
INSERT INTO options values ( 1069,'D. Double the number of nodes you currently have.',FALSE,259) ;
INSERT INTO options values ( 1070,'A. Set up VPC peering and peer each Shared VPC together',FALSE,260) ;
INSERT INTO options values ( 1071,'B. Configure SSH port forwarding on each application to provide connectivity between applications i the different Shared VPCs',FALSE,260) ;
INSERT INTO options values ( 1072,'C. Migrate the protects from the acquired company into your companys Google Cloud organization Re launch the instances in your companies Shared VPC',FALSE,260) ;
INSERT INTO options values ( 1073,'D. Set up a Cloud VPN gateway in each Shared VPC and peer Cloud VPNs',TRUE,260) ;
INSERT INTO options values ( 1074,'A. Use the gsutil mv command lo move the data',FALSE,261) ;
INSERT INTO options values ( 1075,'B. Use the Storage Transfer Service to move the data',TRUE,261) ;
INSERT INTO options values ( 1076,'C. Download the data to a Transfer Appliance and ship it to Google',FALSE,261) ;
INSERT INTO options values ( 1077,'D. Download the data to the on-premises data center and upload it to the Cloud Storage bucket',FALSE,261) ;
INSERT INTO options values ( 1078,'A. Create an aggregated export on the Production folder. Set the log sink to be a Cloud Storage bucket in an operations project',TRUE,262) ;
INSERT INTO options values ( 1079,'B. Create an aggregated export on the Organization resource. Set the tog sink to be a Cloud Storage bucket in an operations project.',FALSE,262) ;
INSERT INTO options values ( 1080,'C. Create log exports in the production projects. Set the log sinks to be a Cloud Storage bucket in an operations project.',FALSE,262) ;
INSERT INTO options values ( 1081,'D. Create tog exports in the production projects. Set the tog sinks to be BigQuery datasets in the production projects and grant IAM access to the operations team to run queries on the dataset',FALSE,262) ;
INSERT INTO options values ( 1082,'A. Enable Private Google Access on sub-b',FALSE,263) ;
INSERT INTO options values ( 1083,'B. Configure Cloud NAT and select sub b m the NAT mapping section',TRUE,263) ;
INSERT INTO options values ( 1084,'C. Configure a bastion host instance in sub a to connect to instances in sub-b ',FALSE,263) ;
INSERT INTO options values ( 1085,'D. Enable Identity Aware Proxy for TCP forwarding for instances in sub-b',FALSE,263) ;
INSERT INTO options values ( 1086,'A. Configure an organization policy to restrict identities by domain',TRUE,264) ;
INSERT INTO options values ( 1087,'B. Configure an organization policy to block creation of service accounts',FALSE,264) ;
INSERT INTO options values ( 1088,'C. Configure Cloud Scheduler to trigger a Cloud Function every hour that removes all users that don''t belong to the Cloud identity domain from all projects.',FALSE,264) ;
INSERT INTO options values ( 1089,'A. Configure an organization policy to restrict identities by domain',TRUE,265) ;
INSERT INTO options values ( 1090,'B. Configure an organization policy to block creation of service accounts',FALSE,265) ;
INSERT INTO options values ( 1091,'C. Configure Cloud Scheduler o trigger a Cloud Function every hour that removes all users that don''t belong to the Cloud identity domain from all projects.',FALSE,265) ;
INSERT INTO options values ( 1092,'D. Create a technical user (e g . crawler@yourdomain com), and give it the protect owner rote at root organization level Write a bash script that  Lists all me IAM rules of all projects within the organization • Deletes all users that do not belong to the company domain Create a Compute Engine instance m a project within the Organization and configure gcloud to be executed with technical user credentials Configure a cron job that executes the bash script every hour.',FALSE,265) ;
INSERT INTO options values ( 1093,'A. Bucket Lock',FALSE,266) ;
INSERT INTO options values ( 1094,'B. Object Versioning',TRUE,266) ;
INSERT INTO options values ( 1095,'C. Object change notification',FALSE,266) ;
INSERT INTO options values ( 1096,'D. Object Lifecycle Management',FALSE,266) ;
INSERT INTO options values ( 1097,'A. Create a Dataflow pipeline to retrieve the data from the external sources. As part of the pipeline use the Cloud Data Loss Prevention (Cloud DLP) API to remove any Pll data Store the result in BigQuery',TRUE,267) ;
INSERT INTO options values ( 1098,'B. Create a Dataflow pipeline to retrieve the data from the external sources. As part of the pipeline store all non-PII data in BigQuery and store all Pll data in a Cloud Storage bucket that has a retention policy set.',FALSE,267) ;
INSERT INTO options values ( 1099,'C. Ask the external partners to upload an data on Cloud Storage Configure Bucket Lock for the bucket Create a Dataflow pipeline to read the data from the bucket As part of the pipeline, use the Cloud Data Loss Prevention (Cloud DIP) API to remove any Pll data Store the result in BigQuery',FALSE,267) ;
INSERT INTO options values ( 1100,'D. Ask the external partners to import ail data in your BigQuery dataset Create a dataflow pipeline to copy the data into a new table As part of the Dataflow bucket skip all data in columns that have Pll data',FALSE,267) ;
INSERT INTO options values ( 1101,'A. Use the Data Transfer appliance to perform an offline migration',TRUE,268) ;
INSERT INTO options values ( 1102,'B. Use a commercial partner ETL solution to extract the data from the on-premises database and upload it into Cloud Storage',FALSE,268) ;
INSERT INTO options values ( 1103,'C. Develop a Dataflow job to read data directly from the database and write it into Cloud Storage D. Compress the data and upload it with gsutil -m to enable multi-threaded copy',FALSE,268) ;
INSERT INTO options values ( 1104,'A. Create a Google Group per department and add all department members to their respective groups Create a folder per department and grant the respective group the required 1AM permissions at the folder level Add the projects under the respective folders',TRUE,269) ;
INSERT INTO options values ( 1105,'B. Grant all department members the required 1AM permissions for their respective projects ',FALSE,269) ;
INSERT INTO options values ( 1106,'C. Create a Google Group per department and add all department members to their respective groups Grant each group the required I AM permissions for their respective projects',FALSE,269) ;
INSERT INTO options values ( 1107,'D. Create a folder per department and grant the respective members of the department the required 1AM permissions at the folder level. Structure all projects for each department under the respective folders',FALSE,269) ;
INSERT INTO options values ( 1108,'A. Use a package manager to install gcloud on your workstations instead of installing it manually',FALSE,270) ;
INSERT INTO options values ( 1109,'B. Create a Compute Engine instance and install gcloud on the instance Connect to this instance via SSH to always use the same gcloud installation when interacting with Google Cloud',FALSE,270) ;
INSERT INTO options values ( 1110,'C. Install gcloud on all of your workstations Run the command gcloud components auto-update on each workstation',FALSE,270) ;
INSERT INTO options values ( 1111,'D. Use Google Cloud Shell in the Google Cloud Console to interact with Google Cloud',TRUE,270) ;
INSERT INTO options values ( 1112,'A. Set up a filter in Cloud Logging and a topic in Pub/Sub to publish the logs',FALSE,271) ;
INSERT INTO options values ( 1113,'B. Set up a Cloud Logging Dashboard titled Cloud VPN Logs, and then add a chart that queries for the VPN metrics over a one-year time period',FALSE,271) ;
INSERT INTO options values ( 1114,'C. Enable the Compute Engine API and then enable logging on the firewall rules that match the traffic you want to save',FALSE,271) ;
INSERT INTO options values ( 1115,'D. Set up a filter in Cloud Logging and a Cloud Storage bucket as an export target for the logs you want to save',TRUE,271) ;
INSERT INTO options values ( 1116,'A. Configure liveness and readiness probes in the Pod specification ',TRUE,272) ;
INSERT INTO options values ( 1117,'B. Configure an uptime alert in Cloud Monitoring',FALSE,272) ;
INSERT INTO options values ( 1118,'C. Create a Scheduled Task to check whether the application is available ',FALSE,272) ;
INSERT INTO options values ( 1119,'D. Configure health checks on the managed instance group',FALSE,272) ;
INSERT INTO options values ( 1120,'A. 1 From the dataset where you have the source data, create views of tables that you want to share, excluding Pll 2 Assign an appropriate project-level IAM role to the members of the data science team 3 Assign access controls to the dataset that contains the view',FALSE,273) ;
INSERT INTO options values ( 1121,'B. 1 From the dataset where you have the source data, create materialized views of tables that you want to share excluding Pll 2 Assign an appropriate project-level IAM role to the members of the data science team 3. Assign access controls to the dataset that contains the view.',FALSE,273) ;
INSERT INTO options values ( 1122,'C. 1 Create a dataset for the data science team 2 Create views of tables that you want to share excluding Pll 3 Assign an appropriate project-level IAM role to the members of the data science team 4 Assign access controls to the dataset that contains the view 5 Authorize the view to access the source dataset ',TRUE,273) ;
INSERT INTO options values ( 1123,'D. 1. Create a dataset for the data science team. 2. Create materialized views of tables that you want to share, excluding Pll 3. Assign an appropriate project-level IAM role to the members of the data science team 4 Assign access controls to the dataset that contains the view 5 Authorize the view to access the source dataset',FALSE,273) ;
INSERT INTO options values ( 1124,'A. 1 Create a second Google Workspace account and Organization 2 Grant all developers the Project Creator IAM role on the new Organization 3 Move the developer projects into the new Organization 4 Set the policies for all projects on both Organizations. 5 Additionally set the production policies on the original Organization',FALSE,274) ;
INSERT INTO options values ( 1125,'B. 1 Create a folder under the Organization resource named Production 2 Grant all developers the Project Creator IAM role on the Organization 3. Move the developer projects into the Organization 4 Set the policies for all projects on the Organization 5 Additionally set the production policies on the Production folder',FALSE,274) ;
INSERT INTO options values ( 1126,'C. 1 Create folders under the Organization resource named "Development" and "Production" 2 Grant all developers the Project Creator IAM role on the ""Development1 folder 3. Move the developer projects into the "Development" folder 4 Set the policies for all projects on the Organization 5 Additionally set the production policies on the "Production" folder ',TRUE,274) ;
INSERT INTO options values ( 1127,'D. 1 Designate the Organization for production projects only 2 Ensure that developers do not have the Project Creator IAM role on the OrganizationQuestions and 3 Create development projects outside of the Organization using the developer Google Workspace accounts 4 Set the policies for all projects on the Organization 5 Additionally set the production policies on the individual production projects',FALSE,274) ;
